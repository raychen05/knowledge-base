## 1. Background

In the past, our data source for creating dimension and metrics data for the InCites Analytical application was the UDM data. However, this approach has proven to be highly inefficient, as it typically takes at least 15 days for the IMS team to process and deliver the UDM data to us. This significant delay in data refresh hampers our ability to provide timely and accurate real-time data to our customers, obstructing our goal to deliver up-to-date insights.

To meet our customers' requirements for analyzing the performance and productivity of their researchers, organizations, or publishers based on real-time data, it has become imperative to redesign our data pipeline framework. Our customers demand quick and instant access to new documents and metrics data to make informed decisions and stay competitive.

To address these challenges and improve our data delivery capabilities, we are migrating from the UDM data system to a modern data pipeline framework leveraging Databricks and Delta Lake technology. This new framework is designed to support near real-time data ingestion, management, and updates, ensuring that we can deliver the most current data to our customers with minimal latency.

## Reasons for Redesigning the Data Pipeline Framework

### Inefficiency of the Existing System:

- The current process of relying on UDM data, which takes 15 days for processing and delivery, is too slow to meet the needs of real-time data updates.
- Delays in data refresh prevent us from providing timely insights, affecting customer satisfaction and our competitive edge.

### Customer Demand for Real-Time Data:

- Our customers require up-to-date data to analyze the performance and productivity of their researchers, organizations, and publishers.
- Timely access to new documents and metrics data is crucial for making informed decisions and staying ahead in their respective fields.
- 
### Advanced Technology for Enhanced Performance:

- By adopting Databricks and Delta Lake, we can leverage cutting-edge technology to build a robust and efficient data pipeline.
- Databricks offers a unified platform for data processing, analytics, and machine learning, while Delta Lake provides ACID transactions, scalable metadata handling, and unified streaming and batch data processing.
- 
### Improved Data Management and Query Performance:

- Delta Lake's ability to manage data with ACID transactions ensures data integrity and consistency.
- Enhanced indexing and optimization capabilities in Delta Lake enable faster and more efficient querying of large datasets.

### Scalability and Flexibility:

- The new framework on Amazon S3 using Parquet format and Delta Lake allows for scalable and flexible data storage and processing.
- It supports schema evolution, ensuring that our data pipelines can adapt to changes in data structure over time without disruption.

## Objectives of the New Data Pipeline System

### Real-Time Data Ingestion and Processing:

- Implement a data pipeline that can ingest and process data in near real-time, minimizing delays and ensuring that the latest data is always available.

### Seamless Data Updates and Delivery:

- Enable continuous and seamless updates to the data, ensuring that our customers receive the most current information without waiting for periodic refresh cycles.

### Enhanced Customer Experience:

- Provide our customers with the ability to analyze the performance and productivity of their entities based on the latest data, enhancing their decision-making processes and overall satisfaction.

### Operational Efficiency:

- Reduce the time and effort required to process and deliver data, improving operational efficiency and allowing our teams to focus on higher-value tasks.
- 
By transitioning to this new data pipeline framework, we aim to overcome the limitations of the UDM data system and deliver a superior, real-time data experience to our customers, empowering them to make data-driven decisions swiftly and effectively.


## 2. Key Points with WoS Product-Ready Data in WoS Enterprise Delta Lake:

#### Key Benefits 
- End prodcut centric. able to deliver product specific features quickly and easily
- Local integration and augmentation to allow fast turnaround of data integration from various sources (e.g. with the "pull" option)
- Support all essential data delivery scenarios (NRT, batch, baseline)
- Maintains data integrity and consistency. keeping WoS product family in sync with each other
- Support evolution path from InCites to RI, or other product (avoid dramatic architectural revemp) and minimize the effort and impact.

#### Other Benefits
- Fully supports data enrichment, augmentation, and the addition of new features.
- Adapts to consume any data sources, types (batch or stream), and formats directly using standard contracts, reducing intermediate processes to shorten the time for new data readiness.
- Adapts to be a product-ready data provider for any application and other data sources.
- Fully supports various types of data updates: NRT data updates, incremental, and baseline updates in a consistent manner.
- Supports the development and delivery of new features to the product quickly without the need to redo everything from the data source.
- Maintains data integrity and consistency at the product level.
- With the 'pull' approach, which involves contracting to input data directly from the data source. This eliminates the need for other parties to deliver the data and decouples the source data from the product & application requirements. This approach minimizes data dependency for most use cases and increases flexibility, allowing application side to retrieve whatever data is needed for new features.