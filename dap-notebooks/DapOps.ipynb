{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2c54e055-f336-422e-9423-1f0bc1065a5d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### 1. Setup Env Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "559ffc0e-7b15-4e6f-9a10-0d1a981166b6",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "setup param"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36msource_catalog\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"ag_content_ims_acs\"\u001b[39m\n",
       "\u001b[36msource_environment\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"prod\"\u001b[39m\n",
       "\u001b[36msource_version\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"\"\u001b[39m\n",
       "\u001b[36mtarget_catalog\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"ag_ra_search_analytics_data\"\u001b[39m\n",
       "\u001b[36mtarget_environment\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"dev\"\u001b[39m\n",
       "\u001b[36mtarget_version\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"v1_0\"\u001b[39m\n",
       "\u001b[36mpipeline_name\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"agra-sa-doc-wos-pipeline\"\u001b[39m"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//  pass the parameters\n",
    "dbutils.widgets.text(\"source_catalog\", \"ag_content_ims_acs\")\n",
    "dbutils.widgets.text(\"source_environment\", \"prod\")\n",
    "dbutils.widgets.text(\"source_version\", \"\")\n",
    "\n",
    "dbutils.widgets.text(\"target_catalog\", \"ag_ra_search_analytics_data\")\n",
    "dbutils.widgets.text(\"target_environment\", \"dev\")\n",
    "dbutils.widgets.text(\"target_version\", \"v1_0\")\n",
    "dbutils.widgets.text(\"pipeline_name\", \"\")\n",
    "\n",
    "\n",
    "dbutils.widgets.text(\"metadata_table_prefix\", \"\")\n",
    "\n",
    "// dynamic paramters\n",
    "val source_catalog = dbutils.widgets.get(\"source_catalog\")\n",
    "val source_environment = dbutils.widgets.get(\"source_environment\")\n",
    "val source_version = dbutils.widgets.get(\"source_version\")\n",
    "val target_catalog = dbutils.widgets.get(\"target_catalog\")\n",
    "val target_environment = dbutils.widgets.get(\"target_environment\")\n",
    "val target_version = dbutils.widgets.get(\"target_version\")\n",
    "val pipeline_name = dbutils.widgets.get(\"pipeline_name\")\n",
    "val metadata_table_prefix = dbutils.widgets.get(\"metadata_table_prefix\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aca93c25-41a2-4b2f-829b-0042e9dbe5f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### 2. DapOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1671ce9c-3595-4ac4-abde-8e5b3209f8ec",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "DapOps"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.{DataFrame, SparkSession, Column}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.functions._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mio.delta.tables.DeltaTable\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mscala.jdk.CollectionConverters._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.sql.Timestamp\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mspark.implicits._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.time.Instant\n",
       "\n",
       "\u001b[39m\n",
       "defined \u001b[32mobject\u001b[39m \u001b[36mDapOps\u001b[39m"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.{DataFrame, SparkSession, Column}\n",
    "import org.apache.spark.sql.functions._\n",
    "import io.delta.tables.DeltaTable\n",
    "import scala.jdk.CollectionConverters._\n",
    "import java.sql.Timestamp\n",
    "import spark.implicits._\n",
    "import java.time.Instant\n",
    "\n",
    "object DapOps {\n",
    "\n",
    "  // ---------------------------------------------------------\n",
    "  // 1.  define the immutable variables: schemas, watermark tables, pipeline, etc.\n",
    "  // ---------------------------------------------------------\n",
    "  private val tablePrefix = SchemaResolver.OPS_TABLE_PREFIX\n",
    "\n",
    "  val DAP_SCHEMA_OPS = SchemaResolver.OPS_SCHEMA\n",
    "  //val DAP_SCHEMA_OPS = \"ag_ra_search_analytics_data_dev.sandbox_v1_0\" // for test only\n",
    "\n",
    "  val WATERMARK = s\"${tablePrefix}${DAP_SCHEMA_OPS}.dap_watermarks\"\n",
    "  val WATERMARK_HISTORY = s\"${DAP_SCHEMA_OPS}.dap_watermark_history\"\n",
    "  val CHECKPOINT = s\"${tablePrefix}${DAP_SCHEMA_OPS}.dap_checkpoints\"\n",
    "  val CHECKPOINT_HISTORY = s\"${DAP_SCHEMA_OPS}.dap_checkpoint_history\"\n",
    "  val PIPELINE_TASK_RUN = s\"${tablePrefix}${DAP_SCHEMA_OPS}.dap_pipeline_task_runs\"\n",
    "\n",
    "  val REGISTRY = s\"${DAP_SCHEMA_OPS}.dap_pipeline_registry\"\n",
    "  val PIPELINE_TASK_UPSTREAM = s\"${DAP_SCHEMA_OPS}.dap_pipeline_task_upstream\"\n",
    "\n",
    "  val PIPELINE_META_INSERT_SQL_FILE = \"insert_dap_pipeline_registry.sql\"\n",
    "  val TASK_META_INSERT_SQL_FILE = \"insert_dap_task_upstream.sql\"\n",
    "\n",
    "\n",
    "  // ---------------------------------------------------------\n",
    "  // 2  define the functions for Ops tables\n",
    "  // ---------------------------------------------------------\n",
    "\n",
    "  // Function to completely remove all OPS tables - danger!\n",
    "  def dropOpsTables(\n",
    "    dryRun:Boolean = true\n",
    "    ): Unit = {\n",
    "    if(!dryRun){\n",
    "      spark.sql(s\"DROP TABLE IF EXISTS $WATERMARK\")\n",
    "      spark.sql(s\"DROP TABLE IF EXISTS $CHECKPOINT\")\n",
    "      spark.sql(s\"DROP TABLE IF EXISTS $WATERMARK_HISTORY\")\n",
    "      spark.sql(s\"DROP TABLE IF EXISTS $CHECKPOINT_HISTORY\")\n",
    "      spark.sql(s\"DROP TABLE IF EXISTS $REGISTRY\")\n",
    "      spark.sql(s\"DROP TABLE IF EXISTS $PIPELINE_TASK_RUN\")\n",
    "      spark.sql(s\"DROP TABLE IF EXISTS $PIPELINE_TASK_UPSTREAM\")\n",
    "    }\n",
    "  }\n",
    "\n",
    "  // Function to create Ops tables if not exists\n",
    "  def createOpsTables(\n",
    "    dryRun: Boolean = false\n",
    "    ): Unit = {\n",
    "    if(dryRun) return\n",
    "    //  data for control & tracking\n",
    "    createCheckpointTable(CHECKPOINT)\n",
    "    createCheckpointTable(CHECKPOINT_HISTORY)\n",
    "    createMatermarkTable(WATERMARK)\n",
    "    createMatermarkTable(WATERMARK_HISTORY) \n",
    "    createPipelineTaskRubTable(PIPELINE_TASK_RUN)\n",
    "    // data for meta\n",
    "    createRegistryTable(REGISTRY)\n",
    "    createPipelineUpstreamTable(PIPELINE_TASK_UPSTREAM)\n",
    "\n",
    "  }\n",
    "\n",
    "  def InsertPieplieMeta(): Unit ={\n",
    "\n",
    "      executeSqlStatements(\n",
    "        sqlStatements =  DapIO.readSQL(PIPELINE_META_INSERT_SQL_FILE),\n",
    "        stopOnError = true\n",
    "      )\n",
    "   \n",
    "      executeSqlStatements(\n",
    "        sqlStatements =  DapIO.readSQL(TASK_META_INSERT_SQL_FILE),\n",
    "        stopOnError = true\n",
    "      )\n",
    "  }\n",
    "\n",
    "  def createMatermarkTable(tableName: String, pipeline_name: String=\"\"): Unit = {\n",
    "    spark.sql(\n",
    "      s\"\"\"\n",
    "         |CREATE TABLE IF NOT EXISTS ${tableName} (\n",
    "         |  batch_id LONG,\n",
    "         |  table_name STRING,\n",
    "         |  start_version BIGINT,\n",
    "         |  end_version BIGINT,\n",
    "         |  last_processed_version BIGINT,\n",
    "         |  latest_available_version BIGINT,\n",
    "         |  start_ts TIMESTAMP,\n",
    "         |  end_ts TIMESTAMP,\n",
    "         |  cdf_enabled BOOLEAN,\n",
    "         |  status STRING,\n",
    "         |  error_message STRING,\n",
    "         |  update_ts TIMESTAMP,\n",
    "         |  updated_by STRING\n",
    "         |) USING DELTA\n",
    "       \"\"\".stripMargin)\n",
    "  }\n",
    "\n",
    "  def createCheckpointTable(tableName: String): Unit = {\n",
    "    spark.sql(\n",
    "      s\"\"\"\n",
    "         |CREATE TABLE IF NOT EXISTS  ${tableName} (\n",
    "         |  pipeline_name STRING,\n",
    "         |  batch_id LONG,\n",
    "         |  start_ts TIMESTAMP,\n",
    "         |  end_ts TIMESTAMP,\n",
    "         |  processed_ts LONG,\n",
    "         |  status STRING,\n",
    "         |  rows_read BIGINT,\n",
    "         |  rows_written BIGINT,\n",
    "         |  retry LONG,\n",
    "         |  error_message STRING,\n",
    "         |  update_ts TIMESTAMP,\n",
    "         |  updated_by STRING\n",
    "         |) USING DELTA\n",
    "         |PARTITIONED BY (pipeline_name);\n",
    "       \"\"\".stripMargin)\n",
    "  }\n",
    "\n",
    "  def createRegistryTable(tableName: String): Unit = {\n",
    "   spark.sql(\n",
    "      s\"\"\"\n",
    "         |CREATE TABLE IF NOT EXISTS ${tableName} (\n",
    "         |  pipeline_name STRING,\n",
    "         |  type STRING,\n",
    "         |  product STRING,\n",
    "         |  owner STRING,\n",
    "         |  email STRING,\n",
    "         |  description STRING,\n",
    "         |  upstream_tables ARRAY<STRING>,\n",
    "         |  update_ts TIMESTAMP,\n",
    "         |  updated_by STRING\n",
    "         |) USING DELTA\n",
    "       \"\"\".stripMargin)\n",
    "  }\n",
    "\n",
    "  def createPipelineTaskRubTable(tableName: String): Unit = {\n",
    "    spark.sql(\n",
    "      s\"\"\"\n",
    "        |CREATE TABLE IF NOT EXISTS ${tableName} (\n",
    "         |  pipeline_name        STRING,\n",
    "         |  run_id               STRING,\n",
    "         |  task_name            STRING,\n",
    "         |  status               STRING,   \n",
    "         |  attempt              INT,\n",
    "         |  started_at           TIMESTAMP,\n",
    "         |  completed_at         TIMESTAMP,\n",
    "         |  error_message        STRING,\n",
    "         |  created_at           TIMESTAMP,\n",
    "         |  updated_at           TIMESTAMP\n",
    "         |) USING DELTA\n",
    "         |PARTITIONED BY (pipeline_name, task_name);\n",
    "        \"\"\".stripMargin)\n",
    "  }\n",
    "\n",
    "  def createPipelineUpstreamTable(tableName: String): Unit = {\n",
    "    spark.sql(\n",
    "      s\"\"\"\n",
    "        |CREATE TABLE IF NOT EXISTS ${tableName} (\n",
    "         |  pipeline_name        STRING,\n",
    "         |  task_name            STRING,\n",
    "         |  upstream_tables      ARRAY<STRING>,  \n",
    "         |  updated_by           STRING,\n",
    "         |  updated_at           TIMESTAMP\n",
    "         |) USING DELTA\n",
    "         |PARTITIONED BY (pipeline_name, task_name);\n",
    "        \"\"\".stripMargin)\n",
    "  }\n",
    "\n",
    "  def executeSqlStatements(\n",
    "      sqlStatements: List[String],\n",
    "      stopOnError: Boolean = true\n",
    "  ): Unit = {\n",
    "\n",
    "    // Filter out empty statements (trim whitespace)\n",
    "    val statements = sqlStatements.map(_.trim).filter(_.nonEmpty)\n",
    "\n",
    "    statements.zipWithIndex.foreach { case (stmt, idx) =>\n",
    "      try {\n",
    "        println(s\"Executing SQL statement #${idx + 1}\")\n",
    "        spark.sql(stmt)\n",
    "      } catch {\n",
    "        case e: Exception =>\n",
    "          println(s\"Failed SQL statement #${idx + 1}:\\n$stmt\")\n",
    "          if (stopOnError) throw e\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "720405a7-9091-4802-904c-c1019d72475c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### 3. Testing DapOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "a61892b1-61a2-447c-b5b4-0bab85eb42e1",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "DapOps.dropTables"
    }
   },
   "outputs": [],
   "source": [
    " // dryRun:Boolean = true\n",
    " DapOps.dropOpsTables(true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b6f8edf-2623-4e00-b556-f1044860b7ea",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "DapOps.createTables"
    }
   },
   "outputs": [],
   "source": [
    "DapOps.createOpsTables()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "scala",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "incremental-delta",
   "widgets": {
    "pipeline_name": {
     "currentValue": "agra-sa-doc-wos-pipeline",
     "nuid": "dbffeef3-68fa-442f-9750-79c3d37742ba",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "pipeline_name",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "",
      "label": null,
      "name": "pipeline_name",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "source_catalog": {
     "currentValue": "ag_content_ims_acs",
     "nuid": "f3c3cc47-a1e0-4b4d-8ca3-81a99fbe7622",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "ag_content_ims_acs",
      "label": null,
      "name": "source_catalog",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "ag_content_ims_acs",
      "label": null,
      "name": "source_catalog",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "source_environment": {
     "currentValue": "prod",
     "nuid": "00562427-7670-41ec-8f58-a714c105fef5",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "prod",
      "label": null,
      "name": "source_environment",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "prod",
      "label": null,
      "name": "source_environment",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "source_version": {
     "currentValue": "",
     "nuid": "086a8b69-38bd-4dc3-b21f-1090e25bd714",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "source_version",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "",
      "label": null,
      "name": "source_version",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "target_catalog": {
     "currentValue": "ag_ra_search_analytics_data",
     "nuid": "15b4e45b-25a6-427d-aca3-cbab17757a99",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "ag_ra_search_analytics_data",
      "label": null,
      "name": "target_catalog",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "ag_ra_search_analytics_data",
      "label": null,
      "name": "target_catalog",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "target_environment": {
     "currentValue": "dev",
     "nuid": "8736d6e4-6c27-42d8-8642-4a95e9cc8e77",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "dev",
      "label": null,
      "name": "target_environment",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "dev",
      "label": null,
      "name": "target_environment",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    },
    "target_version": {
     "currentValue": "v1_0",
     "nuid": "c9eea331-ef3f-42f8-8819-fc4ee09e0fcd",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "v1_0",
      "label": null,
      "name": "target_version",
      "options": {
       "validationRegex": null,
       "widgetDisplayType": "Text"
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "defaultValue": "v1_0",
      "label": null,
      "name": "target_version",
      "options": {
       "autoCreated": null,
       "validationRegex": null,
       "widgetType": "text"
      },
      "widgetType": "text"
     }
    }
   }
  },
  "language_info": {
   "name": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
