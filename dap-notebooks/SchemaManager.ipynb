{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949cfdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "object SchemaManager {\n",
    "\n",
    "  // ---------- Schema operations ----------\n",
    "\n",
    "    // create all DAP schemas\n",
    "    def createDapSchemas(): Unit = {\n",
    "\n",
    "      SchemaResolver.DAP_SCHEMAS.foreach { schema => \n",
    "        createSchema(schema) \n",
    "      }\n",
    "    }\n",
    "    \n",
    "    def createSchema(\n",
    "      schemaName: String\n",
    "    ): Unit = {\n",
    "\n",
    "      spark.sql(s\"CREATE SCHEMA IF NOT EXISTS $schemaName\")\n",
    "    }\n",
    "\n",
    "    // drop all DAP tabls & schema - DANGER!\n",
    "    // removed for safty\n",
    "\n",
    "    def purgeSchema(\n",
    "      schemaName: String,\n",
    "      cascade: Boolean = false\n",
    "    ): Unit = {\n",
    "\n",
    "      val cascadeSql = if (cascade) \"CASCADE\" else \"\"\n",
    "      spark.sql(s\"DROP SCHEMA IF EXISTS $schemaName $cascadeSql\")\n",
    "    }\n",
    "\n",
    "\n",
    "    // ---------- Table operations ----------\n",
    "\n",
    "    // enable CDF for all DAP tables\n",
    "    def enableCdfDapTables(): Unit = {\n",
    "\n",
    "      SchemaResolver.DAP_SCHEMAS.foreach { schema =>\n",
    "\n",
    "        val tableList = spark.sql(s\"SHOW TABLES IN $schema\")\n",
    "          .filter(\"isTemporary = false\") \n",
    "\n",
    "        tableList.collect().map { row =>\n",
    "          val tableName = row.getAs[String](\"tableName\")\n",
    "          val fullTablePath = s\"${schema}.$tableName\"\n",
    "          enableCdf(fullTablePath)\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "\n",
    "    def enableCdf(\n",
    "      tableName: String\n",
    "    ): Unit = {\n",
    "      if (spark.catalog.tableExists(tableName)) {\n",
    "        spark.sql(\n",
    "          s\"\"\" \n",
    "            |ALTER TABLE $tableName\n",
    "            |SET TBLPROPERTIES (delta.enableChangeDataFeed = true);\n",
    "          \"\"\".stripMargin\n",
    "        )\n",
    "      }\n",
    "      else {\n",
    "        println(s\"The table or view `$tableName` cannot be found\")\n",
    "      }\n",
    "\n",
    "    }\n",
    "\n",
    "    // optimize All DAP tables \n",
    "    def optimizeDapTables(\n",
    "      zorderMap: Map[String, Seq[String]] = Map.empty\n",
    "    ): Unit = {\n",
    "\n",
    "      SchemaResolver.DAP_SCHEMAS.foreach { schema =>\n",
    "\n",
    "        val tableList = spark.sql(s\"SHOW TABLES IN $schema\")\n",
    "          .filter(\"isTemporary = false\")\n",
    "\n",
    "        tableList.collect().foreach { row =>\n",
    "          val tableName = row.getAs[String](\"tableName\")\n",
    "          val fullTablePath = s\"${schema}.$tableName\"\n",
    "          // Safely get Z-ORDER columns (empty if not found)\n",
    "          val zorderColsForTable: Seq[String] =\n",
    "            zorderMap.getOrElse(tableName, Seq.empty)\n",
    "\n",
    "          optimizeTable(\n",
    "            tableName = fullTablePath,\n",
    "            zorderCols = zorderColsForTable\n",
    "          )\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "\n",
    "\n",
    "    def optimizeTable(\n",
    "          tableName: String,\n",
    "          zorderCols: Seq[String] = Seq.empty\n",
    "      ): Unit = {\n",
    "        val sql =\n",
    "          if (zorderCols.nonEmpty)\n",
    "            s\"OPTIMIZE $tableName ZORDER BY (${zorderCols.mkString(\", \")})\"\n",
    "          else\n",
    "            s\"OPTIMIZE $tableName\"\n",
    "\n",
    "        spark.sql(sql)\n",
    "    }\n",
    "\n",
    "\n",
    "  // sourceSchema, targetSchema - full path for  catalog, schema and version\n",
    "  // e.g. ag_ra_search_analytics_data_dev.dap_reference_v_1_0_1\n",
    "  def cloneDapSchemas(\n",
    "      sourceSchemaFull: String,\n",
    "      targetSchemaFull: String,\n",
    "  ): Unit = {\n",
    "\n",
    "    println(\n",
    "      s\"Cloning schema: $sourceSchemaFull -> $targetSchemaFull\"\n",
    "    )\n",
    "\n",
    "    // Ensure target schema exists\n",
    "    spark.sql(s\"CREATE SCHEMA IF NOT EXISTS $targetSchemaFull\")\n",
    "\n",
    "    // Get table list from source schema\n",
    "    val tables = spark\n",
    "      .sql(s\"SHOW TABLES IN $sourceSchemaFull\")\n",
    "      .select(\"tableName\")\n",
    "      .collect()\n",
    "      .map(_.getString(0))\n",
    "\n",
    "    // Clone each table\n",
    "    tables.foreach { table =>\n",
    "      val stmt =\n",
    "        s\"\"\"\n",
    "          |CREATE TABLE IF NOT EXISTS $targetSchemaFull.$table\n",
    "          |DEEP CLONE $sourceSchemaFull.$table\n",
    "          |\"\"\".stripMargin\n",
    "\n",
    "      println(stmt)\n",
    "      spark.sql(stmt)\n",
    "    }\n",
    "  }\n",
    "\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "name": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
