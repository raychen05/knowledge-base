 ## ES-Hadoop connector 


This is a classic ES-Hadoop connector pain point ğŸ˜…By default, one bad row can fail the whole Spark â†’ Elasticsearch write, because ES rejects the bulk request.
Below is a battle-tested, Databricks-friendly approach to skip bad rows, keep loading good data, and still keep observability.

Root Cause (why it stops)
When Spark writes to ES via elasticsearch-hadoop:
- Rows are sent in bulk batches
- If any document in the bulk fails (mapping conflict, bad JSON, oversized field, etc.)
- ES returns a bulk error â†’ Spark task fails â†’ job stops
So the fix is:ğŸ‘‰ tolerate document-level failures instead of task-level failure

---

âœ… Recommended Solution (Best Practice)


### 1ï¸âƒ£ Enable ES write error tolerance (MOST IMPORTANT)

Set these ES connector options:

```scala
.option("es.write.operation", "index")
.option("es.batch.write.retry.count", "3")
.option("es.batch.write.retry.wait", "10s")

// ğŸ”‘ critical flags
.option("es.write.rest.error.handlers", "log")
.option("es.write.rest.error.handler.log.level", "WARN")
```

---

### âœ… What this does:

- ES logs failed documents
- Spark continues writing remaining docs
- Job does NOT fail

âš ï¸ Without this, Spark fails hard.

---

### 2ï¸âƒ£ Capture Failed Rows Separately (Highly Recommended)

Logging alone isnâ€™t enough in production. You want bad rows saved.
Use multiple error handlers

```scala
.option(
  "es.write.rest.error.handlers",
  "log,store"
)
.option(
  "es.write.rest.error.handler.store.path",
  "dbfs:/mnt/es_errors/my_index/"
)
```


Result:
- âœ… Successful docs â†’ ES
- âŒ Failed docs â†’ DBFS (JSON)
- ğŸ§  You can reprocess them later

---

### 3ï¸âƒ£ Pre-Validate Rows Before Writing (Avoid ES Failures)

Most ES failures fall into 4 buckets:
1. Null / invalid ID
2. Field type mismatch
3. Oversized strings / arrays
4. Unkown schema chnage

Example: filter obvious bad rows

```scala
val (goodDF, badDF) = df
  .withColumn("is_valid",
    col("id").isNotNull &&
    length(col("title")) < 32766
  )
  .cache()
  .randomSplit(Array(0.999, 0.001)) // optional sampling

goodDF
  .write
  .format("org.elasticsearch.spark.sql")
  .options(esOptions)
  .save("index/_doc")

badDF.write.mode("append").saveAsTable("es_rejects_raw")
```

ğŸ‘‰ This dramatically reduces ES bulk errors

---

### 4ï¸âƒ£ Reduce Blast Radius with Smaller Batches

Large ES batches = one bad doc kills many good ones.
Tune batch size:

```scala
.option("es.batch.size.entries", "500")  // default is 1000+
.option("es.batch.size.bytes", "5mb")
```

This limits damage and speeds retries.

---

### 5ï¸âƒ£ Use Deterministic Document IDs (Avoid Silent Dupes)

Always set:

```scala
.option("es.mapping.id", "id")
```

Why:
- Avoids re-indexing duplicates
- Failed docs can be replayed safely

---

### 6ï¸âƒ£ Production-Grade Pattern (Recommended Architecture)

ğŸ”¹ Step 1: Normalize â†’ Bronze
  - Clean schema
  - Enforce max lengths
  - Cast types
ğŸ”¹ Step 2: Validate â†’ Silver
  - Add is_valid flag
  - Split good vs bad
ğŸ”¹ Step 3: Write â†’ ES
  - Enable error handlers
  - Small batch size
ğŸ”¹ Step 4: Observe
  - Store ES failures
  - Dashboard failure rate
  - Alert if > threshold

---

### 7ï¸âƒ£ Minimal Working Example (Scala / Databricks)


```scala
df.write
  .format("org.elasticsearch.spark.sql")
  .option("es.nodes", "es-host")
  .option("es.port", "9200")
  .option("es.mapping.id", "id")
  .option("es.batch.size.entries", "500")
  .option("es.write.rest.error.handlers", "log,store")
  .option("es.write.rest.error.handler.store.path", "dbfs:/mnt/es_errors/")
  .mode("append")
  .save("my_index/_doc")
```

---

### Summary 

| Problem | Solution |
|---------|----------|
| Job stops on bad rows | `es.write.rest.error.handlers=log,store` |
| Need bad row visibility | Store failed docs to DBFS |
| Reduce failures | Pre-validate schema & length |
| Limit damage | Smaller ES batch size |
| Safe replay | Deterministic document ID |


If you want, I can:
- ğŸ” Build a replay pipeline for failed docs
- ğŸ“Š Add metrics & alerting (failure ratio, bad fields)
- ğŸ§ª Provide unit tests using golden data (ties nicely to your CDC testing work)
Just say the word ğŸ‘Œ


---


## Build a replay pipeline for failed docs



Nice choice ğŸ‘ â€” a replay pipeline is exactly how teams make ES ingestion self-healing instead of fragile.
Below is a production-grade replay design that fits Databricks + ES connector, works incrementally, and wonâ€™t create duplicates.


---

### ğŸ¯ Goal

When ES rejects some documents during Spark write:
- âŒ Failed docs are captured
- ğŸ“¦ Stored durably (DBFS / Delta)
- ğŸ” Replayed automatically after fixes
- ğŸ” Idempotent (safe to retry many times)
- ğŸ“Š Observable

---

### ğŸ§± Overall Architecture

```css
Source DF
   â”‚
   â”œâ”€â”€â–º ES (good docs)
   â”‚
   â””â”€â”€â–º ES Error Store (bad docs)
                â”‚
                â–¼
        Normalize / Fix
                â”‚
                â–¼
          Replay to ES
                â”‚
                â”œâ”€â”€ success â†’ archive
                â””â”€â”€ failure â†’ retry / DLQ
```

---

### 1ï¸âƒ£ Capture Failed Docs in a Structured Way


ES Connector Configuration

```scala
.option("es.write.rest.error.handlers", "log,store")
.option("es.write.rest.error.handler.store.path",
        "dbfs:/mnt/es_errors/my_index/")
```

This generates files like:

```json
{
  "timestamp": "2026-01-29T10:22:31Z",
  "index": "my_index",
  "type": "_doc",
  "id": "123",
  "error": {
    "type": "mapper_parsing_exception",
    "reason": "failed to parse field [age]"
  },
  "document": {
    "id": "123",
    "age": "abc"
  }
}
```

---


### 2ï¸âƒ£ Normalize Failed Docs into a Delta Table


Create a replay staging table (silver-quality).

```scala
val rawErrors = spark.read.json("dbfs:/mnt/es_errors/my_index/*")

val failedDocs = rawErrors.select(
  col("document.*"),
  col("id").as("es_id"),
  col("error.type").as("error_type"),
  col("error.reason").as("error_reason"),
  current_timestamp().as("failed_at"),
  lit(0).as("retry_count"),
  lit("PENDING").as("status")
)

failedDocs.write
  .format("delta")
  .mode("append")
  .saveAsTable("es_failed_docs")
```

---


### 3ï¸âƒ£ Fix / Normalize Before Replay


Apply targeted transformations based on known ES failures.


```scala
val candidates = spark.table("es_failed_docs")
  .filter("status = 'PENDING' AND retry_count < 5")

val fixed = candidates
  .withColumn("age",
    when(col("age").cast("int").isNotNull, col("age").cast("int"))
      .otherwise(lit(null))
  )
  .withColumn("title", substring(col("title"), 1, 32766))
```

ğŸ‘‰ Keep this logic versioned so you know what fix was applied.


---

### 4ï¸âƒ£ Replay to Elasticsearch (Idempotent)


```scala
fixed.write
  .format("org.elasticsearch.spark.sql")
  .option("es.nodes", "es-host")
  .option("es.port", "9200")
  .option("es.mapping.id", "es_id")
  .option("es.write.rest.error.handlers", "log")
  .mode("append")
  .save("my_index/_doc")
```

Because es.mapping.id is set:
- Replay is safe
- Overwrites existing doc if needed
- No duplicates

---

### 5ï¸âƒ£ Update Replay Status (MERGE)


```scala
import io.delta.tables._

val deltaTable = DeltaTable.forName("es_failed_docs")

deltaTable.as("t")
  .merge(
    fixed.select("es_id").as("s"),
    "t.es_id = s.es_id AND t.status = 'PENDING'"
  )
  .whenMatched
  .updateExpr(Map(
    "status" -> "'SUCCESS'",
    "replayed_at" -> "current_timestamp()"
  ))
  .execute()
```

---

### 6ï¸âƒ£ Handle Second-Level Failures (DLQ)

If replay fails again:

```scala
val failedAgain = spark.read.json("dbfs:/mnt/es_errors/my_index/*")

deltaTable.as("t")
  .merge(
    failedAgain.select(col("id").as("es_id")).as("s"),
    "t.es_id = s.es_id"
  )
  .whenMatched
  .updateExpr(Map(
    "retry_count" -> "retry_count + 1",
    "status" -> "CASE WHEN retry_count >= 5 THEN 'DLQ' ELSE 'PENDING' END"
  ))
  .execute()
```

Final states:
- SUCCESS â†’ archived
- PENDING â†’ retried later
- DLQ â†’ manual review

---

### 7ï¸âƒ£ Automate with Databricks Jobs

Suggested Schedule

| Job | Frequency |
|-----|-----------|
| Primary ES load | Continuous / batch |
| Replay job | Every 15â€“30 min |
| DLQ audit | Daily |

---

### 8ï¸âƒ£ Metrics & Alerts (Highly Recommended)


Track:
- % failed docs
- Retry count distribution
- DLQ volume
- Top error types

Example:

```sql
SELECT error_type, count(*) 
FROM es_failed_docs
WHERE status = 'PENDING'
GROUP BY error_type
```

Alert if:
- Failure rate > 0.5%
- DLQ > threshold

---

### 9ï¸âƒ£ Folder / Table Layout

```css
dbfs:/mnt/es_errors/
  â””â”€â”€ my_index/
        â”œâ”€â”€ raw/
        â”œâ”€â”€ replay/
        â””â”€â”€ archive/
```

Delta Tables:
- es_failed_docs
- es_replay_history
- es_dlq

---

### âœ… Why This Works Well

- âœ” No data loss
- âœ” Fully idempotent
- âœ” Replayable forever
- âœ” Clear audit trail
- âœ” Scales with volume

If you want next:
- ğŸ” Generic replay framework (config-driven per index)
- ğŸ§ª Golden-data tests for replay logic
- ğŸ“Š ES ingest SLO dashboard
- ğŸ”§ Auto-classification of ES errors â†’ fix strategy

Tell me which one you want to tackle next ğŸš€


---


## Save Log to s3

Short answer: yes â€” you can use S3, but not directly as s3://â€¦ in that option. Thereâ€™s an important Databricks + ES-connector nuance here.
Letâ€™s break it down cleanly ğŸ‘‡

### âœ… What does work

âœ” Use DBFS that is backed by S3
This is the recommended + supported approach.

```scala
.option(
  "es.write.rest.error.handler.store.path",
  "dbfs:/mnt/es_errors/"
)
```

If /mnt/es_errors is an S3 mount:

dbfs:/mnt/es_errors  â†’  s3://my-bucket/es_errors/

- ğŸ‘‰ Physically stored in S3, logically accessed as DBFS
- ğŸ‘‰ ES connector is happy
- ğŸ‘‰ Spark permissions + retries work correctly

âŒ What does NOT work

```scala
.option(
  "es.write.rest.error.handler.store.path",
  "s3://my-bucket/es_errors/"
)
```

Why this fails:
- ES-Hadoop does not use Sparkâ€™s FileSystem abstraction
- It expects a Hadoop-compatible FS path
- Direct s3:// paths often fail with:
    - No FileSystem for scheme s3
    - Silent write failures
    - Executor-side permission errors
This is a known limitation of ES-Hadoop.

---

### âœ… Correct Ways to Use S3 (Ranked)

#### ğŸ¥‡ Option 1 â€” DBFS Mount to S3 (BEST)


```scala
dbutils.fs.mount(
  source = "s3a://my-bucket",
  mountPoint = "/mnt/es_errors",
  extraConfigs = Map(
    "fs.s3a.access.key" -> "...",
    "fs.s3a.secret.key" -> "..."
  )
)
```

Then:

```scala
.option(
  "es.write.rest.error.handler.store.path",
  "dbfs:/mnt/es_errors/"
)
```

- âœ” Fully supported
- âœ” Secure
- âœ” Easy replay pipeline
- âœ” Works with Delta

---

#### ğŸ¥ˆ Option 2 â€” Unity Catalog External Location (Modern)

If youâ€™re on UC:

External Location:
  s3://my-bucket/es_errors/

Access via:

dbfs:/Volumes/catalog/schema/es_errors/
Then:

```scala
.option(
  "es.write.rest.error.handler.store.path",
  "dbfs:/Volumes/catalog/schema/es_errors/"
)
```

- âœ” IAM-based access
- âœ” Cleaner governance
- âœ” Works great with Delta

---

#### ğŸ¥‰ Option 3 â€” Local FS (NOT recommended)

file:/tmp/es_errors/

- âŒ Executor-local
- âŒ Lost on restart
- âŒ No replay durability


#### ğŸ§  Why ES Error Store Needs DBFS

The ES error handler:
- Writes from executors
- Uses Hadoop FS APIs
- Needs atomic file creation
- Needs retry-safe storage

DBFS solves all of this; raw S3 does not.

---

### ğŸ” Replay Pipeline Compatibility

Once errors are stored in DBFS-backed S3:

```scala
spark.read.json("dbfs:/mnt/es_errors/*")
```

- âœ” Parallel reads
- âœ” Schema evolution
- âœ” Delta-friendly
- âœ” Cheap storage

---

### âœ… Final Recommendation

YES, you can absolutely use S3 BUT always go through DBFS (mount or UC Volume)
âœ” Do this

"dbfs:/mnt/es_errors/"

âŒ Not this

"s3://my-bucket/es_errors/"

If you want, I can:
- ğŸ” Design an IAM + UC external location setup
- ğŸ“ Give a partitioned S3 layout for multi-index replay
- ğŸ§ª Add replay tests that read from mounted S3
- ğŸ›¡ Add encryption & retention policies


---

## Design an IAM + UC external location setup

Perfect â€” this is the cleanest, future-proof setup for what youâ€™re building 
ğŸ‘ Below is a production-grade IAM + Unity Catalog External Location design tailored for:
- ES error capture
- Replay pipelines
- Least-privilege security
- Auditing & governance
- 
Iâ€™ll keep it concrete and Databricks-ready.

---

### ğŸ¯ Target Architecture

```css
Elasticsearch
   â”‚
   â”œâ”€â”€ good docs â†’ ES index
   â”‚
   â””â”€â”€ failed docs
          â”‚
          â–¼
DBFS path (UC Volume)
dbfs:/Volumes/main/ops/es_errors/
          â”‚
          â–¼
S3 bucket (External Location)
```

s3://company-data-prod/es/es_errors/

**Key idea**:
ES connector writes to DBFS â†’ DBFS maps to UC Volume â†’ UC Volume maps to S3 via IAM role

---

### 1ï¸âƒ£ S3 Bucket Design (Foundation)

Bucket

s3://company-data-prod/
Folder layout (important for replay & governance)

```css
es/
 â””â”€â”€ es_errors/
      â”œâ”€â”€ index=my_index/
      â”‚    â”œâ”€â”€ dt=2026-01-29/
      â”‚    â””â”€â”€ dt=2026-01-30/
      â”œâ”€â”€ index=another_index/
      â””â”€â”€ _archive/
```

- âœ” Partitionable
- âœ” Cheap replay scans
- âœ” Easy lifecycle rules

---

### 2ï¸âƒ£ IAM Role (Least Privilege)

IAM Role

databricks-uc-es-errors-role
Trust Policy (Databricks AWS account)

```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Principal": {
        "AWS": "arn:aws:iam::<DATABRICKS_AWS_ACCOUNT_ID>:root"
      },
      "Action": "sts:AssumeRole",
      "Condition": {
        "StringEquals": {
          "sts:ExternalId": "<DATABRICKS_EXTERNAL_ID>"
        }
      }
    }
  ]
}
```

Permissions Policy (Minimal)
```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "EsErrorStoreAccess",
      "Effect": "Allow",
      "Action": [
        "s3:PutObject",
        "s3:GetObject",
        "s3:DeleteObject",
        "s3:ListBucket"
      ],
      "Resource": [
        "arn:aws:s3:::company-data-prod",
        "arn:aws:s3:::company-data-prod/es/es_errors/*"
      ]
    }
  ]
}
```

- ğŸš« No access to other datasets
- ğŸš« No wildcard buckets

---

### 3ï¸âƒ£ Create UC Storage Credential

Run once as UC admin:

```sql
CREATE STORAGE CREDENTIAL es_error_cred
WITH IAM_ROLE 'arn:aws:iam::<ACCOUNT_ID>:role/databricks-uc-es-errors-role';
```

Verify:
```sql
DESCRIBE STORAGE CREDENTIAL es_error_cred;
```

---

### 4ï¸âƒ£ Create External Location

```sql
CREATE EXTERNAL LOCATION es_error_location
URL 's3://company-data-prod/es/es_errors/'
WITH (STORAGE CREDENTIAL es_error_cred);
```

Validation:
```sql
DESCRIBE EXTERNAL LOCATION es_error_location;
```

---

### 5ï¸âƒ£ Create UC Volume (This is the Key Step)

Volumes give you a DBFS-style path, which ES connector requires.
```sql
CREATE VOLUME main.ops.es_errors
LOCATION 's3://company-data-prod/es/es_errors/';
```

Resulting path:

dbfs:/Volumes/main/ops/es_errors/

âœ” ES-Hadoop compatible
âœ” IAM governed
âœ” Audited by UC

---

### 6ï¸âƒ£ Grant Access (Fine-Grained)

```sql
GRANT READ, WRITE
ON VOLUME main.ops.es_errors
TO `data-platform-es-writer`;
```

Optional read-only for analysts:
```sql
GRANT READ
ON VOLUME main.ops.es_errors
TO `data-observability`;
```

---

### 7ï¸âƒ£ ES Connector Configuration (Final)

Use only DBFS path:

```scala
.option(
  "es.write.rest.error.handlers",
  "log,store"
)
.option(
  "es.write.rest.error.handler.store.path",
  "dbfs:/Volumes/main/ops/es_errors/index=my_index/dt=2026-01-30/"
)
```

ğŸ’¡ You can dynamically inject:
- index
- date
- env (dev/prod)

---

### 8ï¸âƒ£ Replay Pipeline Reads (Spark / Delta)

```scala
val errors = spark.read.json(
  "dbfs:/Volumes/main/ops/es_errors/index=my_index/*"
)
```

Or materialize to Delta:
```scala
errors.write
  .format("delta")
  .mode("append")
  .saveAsTable("ops.es_failed_docs")
```

---

### 9ï¸âƒ£ Lifecycle & Cost Control (Highly Recommended)

**S3 Lifecycle Rule**

| Data | Action |
|------|--------|
| Raw ES errors | 30 days |
| Replayed success | Glacier after 60 days |
| DLQ | Retain 180 days |

---

### 10ï¸âƒ£ Why This Setup Is â€œCorrectâ€

- âœ” ES-Hadoop compatible
- âœ” Cloud-native IAM
- âœ” Unity Catalog governance
- âœ” Auditable access
- âœ” No hardcoded secrets
- âœ” Replay-safe
- âœ” Future-proof (DBFS mounts are legacy)

---

### ğŸ” Security Model Summary

| Layer | Responsibility |
|-------|----------------|
| IAM Role | S3 access |
| UC Storage Credential | Identity binding |
| External Location | Path scoping |
| Volume | Runtime access |
| Grants | Who can write/read |


Want to go further?
I can next:
- ğŸ” Make this multi-index / multi-env config-driven
- ğŸ“Š Add replay SLA dashboards
- ğŸ§ª Add golden-data tests for replay
- ğŸš¨ Add auto-quarantine for mapping errors
- ğŸ§© Package this as a reusable ES ingestion framework

---


### 1ï¸âƒ£ Volume paths in Unity Catalog

If you have a catalog volume like:
```sh
/Volumes/catalog_name/schema_name/folder_name
```

- This is a Databricks-managed volume in Unity Catalog.
- Spark can access files directly using the /Volumes/... path.
- You do NOT need dbfs: prefix in this case.
  
So this works:

```scala
val path = "/Volumes/my_catalog/my_schema/my_folder/errors.json"

val df = spark.read
  .format("json")
  .load(path)

df.show()
```

âœ… Works fine because Databricks automatically resolves the /Volumes/... path through the Unity Catalog volume.


---

### 2ï¸âƒ£ When dbfs: prefix is needed

- dbfs:/ is used for DBFS storage paths (like /FileStore/...)
- Also required for some connectors (like the ES connector), when they donâ€™t automatically resolve /Volumes/....
So for Unity Catalog volumes, dbfs: is not required, but for external DBFS paths, you usually need dbfs:/.

---

### 3ï¸âƒ£ Using a Unity Catalog volume path as ES error log path


You can use the /Volumes/... path directly:

```scala
.option("es.write.rest.error.handlers", "log,store")
.option("es.write.rest.error.handler.store.path", "/Volumes/my_catalog/my_schema/my_folder/es_errors/")
.option("es.write.rest.error.handler.log.level", "WARN")
```

- This will store failed documents in the catalog volume.
- ES connector will write successfully, Spark can read from the same path.

---

### âœ… Key Takeaways

| Storage Type | Path Format | Notes |
|-------------|-------------|-------|
| DBFS FileStore / mounts | `dbfs:/FileStore/...` or `dbfs:/mnt/...` | Use `dbfs:` prefix |
| Unity Catalog volume | `/Volumes/catalog/schema/folder` | `dbfs:` prefix NOT needed |
| ES connector log path | Works with either | Just ensure path is accessible to Spark |


ğŸ’¡ Recommendation: 

- For Unity Catalog volumes, just stick with /Volumes/.... 
- Use dbfs: only if youâ€™re using DBFS-managed paths.




