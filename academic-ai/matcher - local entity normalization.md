
## Local Entity Normalization Pipeline


Yes ‚úÖ ‚Äî building a local entity normalization pipeline for‚Ä®research topics, journals, organizations, countries, and funders is both workable and recommended for your use case (data protection, cost saving, low latency).
This is very similar to author disambiguation / affiliation normalization systems we discussed before, but generalized to multiple entity types.


### üîë Key Idea

- Treat the problem as entity linking (EL) or canonicalization:‚Ä®Map a messy input string ‚Üí a canonical entity in your knowledge base (WOS / InCites master tables).
- This does not require an online LLM.‚Ä®Instead, combine:
  1. String normalization & fuzzy matching
  2. Embedding-based semantic search (FAISS, Qdrant)
  3. Hybrid reranking with context rules (e.g., "MIT" = "Massachusetts Institute of Technology")
  4. Optional local LLM reranker for borderline cases

---

### üß∞ Recommended Models (Local, Lightweight, High-Quality)


- String similarity layer
    - rapidfuzz (fast Levenshtein, token-sort, partial ratio)
- Embedding-based semantic search
    - sentence-transformers (lightweight, accurate):
        - all-MiniLM-L6-v2 (fast, 22M params)
        - multi-qa-MiniLM-L6-cos-v1 (trained for retrieval QA)
        - paraphrase-multilingual-MiniLM-L12-v2 (handles multilingual names)
- Vector index
    - FAISS (fast, in-memory) or Qdrant (persistent, REST API)
- Optional domain-specialized embeddings
    - Train on WOS journal titles, funder names, organizations using contrastive fine-tuning (local + supervised pairs)
    - Hugging Face setfit or sentence-transformers fine-tuning works well

---

### ‚öôÔ∏è Framework


A hybrid normalization pipeline (local):

1. Preprocessing / Normalization
    - Lowercase, strip punctuation, remove stopwords like "University of" vs "Univ"
    - Expand common abbreviations (dictionary-based: "MIT" ‚Üí "Massachusetts Institute of Technology")
2. Candidate Generation
    - Fuzzy string match (rapidfuzz) ‚Üí top 20 candidates
    - Embedding search in FAISS/Qdrant ‚Üí top 50 candidates
3. Candidate Reranking
    - Scoring function:‚Ä®‚Ä®‚Ä®‚Ä®final_score = Œ± - fuzzy_score + Œ≤ - cosine_similarity + Œ≥ - context_score
    - ‚Ä®‚Ä®
    - Context score could use metadata (e.g., country when matching orgs; discipline when matching funders)
4. Disambiguation / Selection
    - Pick top-scoring candidate above threshold
    - If low confidence ‚Üí flag for manual review (optional local LLM reranker)

---

### üèóÔ∏è Example Implementation (Python, Local Only)

```python
from sentence_transformers import SentenceTransformer
import faiss, numpy as np
from rapidfuzz import process

# 1. Load model & FAISS index
model = SentenceTransformer("multi-qa-MiniLM-L6-cos-v1")

# Assume canonical_entities is a list of (id, name)
canonical_entities = [
    ("J001", "Nature"),
    ("J002", "Science"),
    ("J003", "Massachusetts Institute of Technology"),
    ("J004", "National Science Foundation"),
    ("J005", "United States"),
]

names = [x[1] for x in canonical_entities]
embeddings = model.encode(names, normalize_embeddings=True)

# Build FAISS index
dim = embeddings.shape[1]
index = faiss.IndexFlatIP(dim)
index.add(embeddings)

# 2. Function to normalize
def normalize_entity(user_input, top_k=5):
    # Fuzzy candidates
    fuzzy_matches = process.extract(user_input, names, limit=top_k)
    
    # Embedding candidates
    query_vec = model.encode([user_input], normalize_embeddings=True)
    D, I = index.search(query_vec, top_k)
    embedding_matches = [(names[i], float(D[0][j])) for j,i in enumerate(I[0])]
    
    # Merge & rank
    candidates = {}
    for name, score in fuzzy_matches:
        candidates[name] = candidates.get(name, 0) + 0.5*score/100
    for name, score in embedding_matches:
        candidates[name] = candidates.get(name, 0) + 0.5*score
    
    # Pick best
    best_match = max(candidates.items(), key=lambda x: x[1])
    return best_match

print(normalize_entity("NSF"))      # ‚Üí National Science Foundation
print(normalize_entity("MIT"))      # ‚Üí Massachusetts Institute of Technology
print(normalize_entity("Nat Sci"))  # ‚Üí Nature / Science (depending on score)
```

---

### üöÄ Deployment Options


- Lightweight:
    - sentence-transformers + FAISS in-memory (runs on CPU fast enough)
- Enterprise-scale:
    - Qdrant or Elasticsearch + dense vectors
    - API service with REST endpoint for normalization
- Optional Enhancements:
    - Train domain-specific embeddings (on WOS/Incites names) for better accuracy
    - Add context-based reranker (country, field, journal category)

‚úÖ Conclusion:‚Ä®This approach is highly workable locally.‚Ä®It avoids online LLM calls, ensures data protection, reduces cost, and is fast enough for production.‚Ä®Quality can reach >90% match accuracy with a hybrid (fuzzy + embedding + context) pipeline.


---

Great ‚Äî this is absolutely workable and is exactly the right approach if you want data security, cost savings, and performance while matching entities (research topic, journal, organization, country, funder) against Clarivate‚Äôs Web of Science (WoS) and InCites canonical dictionaries.
Here‚Äôs a detailed recommendation on model, framework, and implementation:


### üîπ Why Local Normalization Is Workable

- Canonical dictionaries exist (WoS & InCites provide controlled vocabularies for organizations, journals, countries, funders).
- LLM is overkill for this ‚Äî you don‚Äôt need generative reasoning, just entity resolution and string similarity.
- High accuracy possible with a hybrid approach:
    - Preprocessing + normalization rules
    - Embedding-based semantic similarity
    - Fuzzy matching (typos, abbreviations, variants)
    - Contextual reranking (e.g., country + organization, funder + program)
  
This matches exactly the author disambiguation system you‚Äôre already working on (affiliation matching etc.), so you can extend the same design.

---

### üîπ Recommended Models & Frameworks

1. Text Embedding Models (Local)

Use small, open-source embedding models for semantic similarity. Options:
- BGE-small-en (384d, ~100MB, very fast, high recall on entity matching)
- MiniLM-L6-v2 or all-MiniLM-L12-v2 (SentenceTransformers, very compact)
- GTE-small (General Text Embedding, multilingual, accurate for org/topic names)
üëâ These can run on CPU for cost savings.

2. Fuzzy Matching

Use RapidFuzz (faster & better than FuzzyWuzzy) for:
- Levenshtein distance
- Token sort ratio
- Handling abbreviations & swapped words

3. Vector Database for Search
   
- FAISS (lightweight, local, fast) ‚Äî for embedding search
- Qdrant (if you want REST + hybrid search support)

4. Graph Layer (Optional but Recommended)

For organization hierarchy / alias mapping, you can use:
- Neo4j (graph of institutions, mergers, subsidiaries)
- Helps rerank "University of California" vs "UC Berkeley"

---

### üîπ Implementation Strategy


1. Preprocessing Pipeline

    - Lowercase, remove punctuation, normalize Unicode
    - Expand abbreviations (e.g., "MIT" ‚Üí "Massachusetts Institute of Technology") using alias dictionary
    - Normalize stopwords (e.g., "Univ." ‚Üí "University")

2. Embedding Index

    - Store all canonical WoS & InCites names in FAISS / Qdrant
    - Encode user input with same embedding model
    - Retrieve top-N candidates

3. Hybrid Reranking

    - Combine:
        - Embedding similarity score
        - Fuzzy string similarity score
        - Context signals (e.g., journal field, funder‚Äôs country, topic hierarchy)
    - Final ranking with weighted scoring

4. Caching

    - Store results of frequent queries locally (e.g., Redis)
    - Speeds up repeated normalizations

---

### üîπ Example (Python Prototype)

```python
from sentence_transformers import SentenceTransformer
import faiss
import rapidfuzz

# 1. Load local embedding model
model = SentenceTransformer("BAAI/bge-small-en")  

# 2. Build FAISS index
canonical_names = ["Massachusetts Institute of Technology", 
                   "University of California, Berkeley", 
                   "Carnegie Mellon University"]

embeddings = model.encode(canonical_names, normalize_embeddings=True)
index = faiss.IndexFlatIP(embeddings.shape[1])
index.add(embeddings)

# 3. Normalize user input
user_input = "MIT"
query_vec = model.encode([user_input], normalize_embeddings=True)
D, I = index.search(query_vec, k=3)

# 4. Combine with fuzzy match
candidates = [(canonical_names[i], float(D[0][j])) for j,i in enumerate(I[0])]
for name, score in candidates:
    fuzz_score = rapidfuzz.fuzz.token_sort_ratio(user_input, name) / 100
    combined = 0.6 - score + 0.4 - fuzz_score
    print(f"{user_input} ‚Üí {name}, combined={combined:.2f}")
```

---

### üîπ When to Use LLM (Optional)

You may still optionally use LLM offline (e.g., LLaMA 3 Instruct, Mistral 7B) for:

- Rare edge cases where abbreviation + alias dictionary fails
- Explainability (‚ÄúWhy was ‚ÄòUC Berkeley‚Äô matched to ‚ÄòUniversity of California, Berkeley‚Äô?‚Äù)
But 95% of normalization can be handled without LLM.


‚úÖ Conclusion:

Yes ‚Äî building a local entity normalization pipeline for research topics, journals, organizations, countries, and funders is both workable and the best approach for security, performance, and cost. The hybrid approach (embedding + fuzzy + context + dictionary) is proven in academic name matching (Clarivate, Scopus, ORCID).


---

## A Complete, Production-ready Repo Blueprint 


Awesome‚Äîhere‚Äôs a complete, production-ready repo blueprint for local entity normalization (topics, journals, organizations, countries, funders) that you can plug into WoS/InCites. It‚Äôs hybrid (rules + fuzzy + embeddings + optional graph/context), offline, fast, and extensible.


### Repo layout

```plaintext
entity-normalizer/
‚îú‚îÄ README.md
‚îú‚îÄ pyproject.toml
‚îú‚îÄ src/
‚îÇ  ‚îú‚îÄ normalizer/
‚îÇ  ‚îÇ  ‚îú‚îÄ __init__.py
‚îÇ  ‚îÇ  ‚îú‚îÄ config.py
‚îÇ  ‚îÇ  ‚îú‚îÄ utils_text.py
‚îÇ  ‚îÇ  ‚îú‚îÄ rules/
‚îÇ  ‚îÇ  ‚îÇ  ‚îú‚îÄ normalize_rules.py
‚îÇ  ‚îÇ  ‚îÇ  ‚îú‚îÄ token_maps/
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ  ‚îú‚îÄ common.json        # Univ‚Üíuniversity, &‚Üíand, etc.
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ  ‚îú‚îÄ org_aliases.csv    # ‚ÄúMIT,Massachusetts Institute of Technology‚Äù
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ  ‚îú‚îÄ funder_aliases.csv
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ  ‚îú‚îÄ journal_aliases.csv
‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ  ‚îî‚îÄ country_aliases.csv
‚îÇ  ‚îÇ  ‚îú‚îÄ candidates/
‚îÇ  ‚îÇ  ‚îÇ  ‚îú‚îÄ generator.py          # FAISS + fuzzy
‚îÇ  ‚îÇ  ‚îÇ  ‚îú‚îÄ faiss_index.py
‚îÇ  ‚îÇ  ‚îÇ  ‚îú‚îÄ qdrant_client.py      # optional
‚îÇ  ‚îÇ  ‚îú‚îÄ ranking/
‚îÇ  ‚îÇ  ‚îÇ  ‚îú‚îÄ reranker.py           # hybrid score
‚îÇ  ‚îÇ  ‚îÇ  ‚îú‚îÄ context_features.py   # country, field, ISSN, GRID/ROR hints
‚îÇ  ‚îÇ  ‚îú‚îÄ stores/
‚îÇ  ‚îÇ  ‚îÇ  ‚îú‚îÄ catalog.py            # load WoS/InCites master tables
‚îÇ  ‚îÇ  ‚îÇ  ‚îú‚îÄ cache.py              # optional Redis/SQLite cache
‚îÇ  ‚îÇ  ‚îú‚îÄ entity_types/
‚îÇ  ‚îÇ  ‚îÇ  ‚îú‚îÄ base.py               # abstract normalizer
‚îÇ  ‚îÇ  ‚îÇ  ‚îú‚îÄ journals.py
‚îÇ  ‚îÇ  ‚îÇ  ‚îú‚îÄ organizations.py
‚îÇ  ‚îÇ  ‚îÇ  ‚îú‚îÄ countries.py
‚îÇ  ‚îÇ  ‚îÇ  ‚îú‚îÄ funders.py
‚îÇ  ‚îÇ  ‚îÇ  ‚îî‚îÄ topics.py
‚îÇ  ‚îÇ  ‚îú‚îÄ pipeline.py              # orchestrates steps
‚îÇ  ‚îÇ  ‚îî‚îÄ eval/
‚îÇ  ‚îÇ     ‚îú‚îÄ metrics.py
‚îÇ  ‚îÇ     ‚îî‚îÄ evaluate.py
‚îÇ  ‚îú‚îÄ api/
‚îÇ  ‚îÇ  ‚îú‚îÄ __init__.py
‚îÇ  ‚îÇ  ‚îú‚îÄ main.py                   # FastAPI
‚îÇ  ‚îÇ  ‚îî‚îÄ schemas.py                # Pydantic I/O schemas
‚îÇ  ‚îî‚îÄ cli/
‚îÇ     ‚îî‚îÄ normalize.py              # batch CLI
‚îú‚îÄ data/
‚îÇ  ‚îú‚îÄ catalogs/                    # canonical tables (WoS/InCites)
‚îÇ  ‚îÇ  ‚îú‚îÄ journals.csv              # id,name,issn,eissn,field,aliases
‚îÇ  ‚îÇ  ‚îú‚îÄ orgs.csv                  # id,name,grid,ror,country,aliases
‚îÇ  ‚îÇ  ‚îú‚îÄ funders.csv               # id,name,country,aliases
‚îÇ  ‚îÇ  ‚îú‚îÄ countries.csv             # iso2,iso3,name,aliases
‚îÇ  ‚îÇ  ‚îî‚îÄ topics.csv                # id,name,keywords,aliases
‚îÇ  ‚îú‚îÄ embeddings/
‚îÇ  ‚îÇ  ‚îú‚îÄ model=BAAI-bge-small-en/  # local hf cache or your path
‚îÇ  ‚îÇ  ‚îî‚îÄ indexes/                  # FAISS files *.index + ids.npy
‚îÇ  ‚îî‚îÄ eval/
‚îÇ     ‚îú‚îÄ labeled_pairs.csv         # input_name,entity_type,gold_id
‚îÇ     ‚îî‚îÄ README.md
‚îú‚îÄ configs/
‚îÇ  ‚îú‚îÄ app.yaml
‚îÇ  ‚îî‚îÄ weights.yaml                 # Œ±/Œ≤/Œ≥, thresholds per type
‚îú‚îÄ docker/
‚îÇ  ‚îú‚îÄ Dockerfile
‚îÇ  ‚îî‚îÄ docker-compose.yml           # (optional Redis/Qdrant/Neo4j)
‚îî‚îÄ tests/
   ‚îú‚îÄ test_rules.py
   ‚îú‚îÄ test_candidates.py
   ‚îú‚îÄ test_reranker.py
   ‚îî‚îÄ test_pipeline.py

```

---

### Core logic

---

###  Config (weights & switches)


src/normalizer/config.py

```python
from pathlib import Path
import yaml

class AppConfig:
    def __init__(self, cfg_path: str = "configs/app.yaml"):
        d = yaml.safe_load(open(cfg_path))
        self.model_name = d["embeddings"]["model_name"]       # "BAAI/bge-small-en"
        self.index_path = Path(d["embeddings"]["index_path"]) # "data/embeddings/indexes/journals.faiss"
        self.use_qdrant = d.get("qdrant", {}).get("enabled", False)
        self.cache = d.get("cache", {"enabled": False})
        self.weights = yaml.safe_load(open("configs/weights.yaml"))

CFG = AppConfig()
```


configs/weights.yaml

```yaml
journals:
  alpha_fuzzy: 0.35
  beta_embed: 0.55
  gamma_ctx: 0.10
  threshold: 0.62
organizations:
  alpha_fuzzy: 0.30
  beta_embed: 0.55
  gamma_ctx: 0.15
  threshold: 0.65
funders:
  alpha_fuzzy: 0.30
  beta_embed: 0.60
  gamma_ctx: 0.10
  threshold: 0.63
countries:
  alpha_fuzzy: 0.40
  beta_embed: 0.50
  gamma_ctx: 0.10
  threshold: 0.80
topics:
  alpha_fuzzy: 0.25
  beta_embed: 0.65
  gamma_ctx: 0.10
  threshold: 0.60
```

---

###  Text normalization & rules


src/normalizer/utils_text.py

```python
import re, unicodedata

PUNCT_RE = re.compile(r"[^\w\s]")
WS_RE = re.compile(r"\s+")

def norm_unicode(s: str) -> str:
    return unicodedata.normalize("NFKD", s).encode("ascii", "ignore").decode()

def normalize_text(s: str) -> str:
    s = norm_unicode(s.lower())
    s = PUNCT_RE.sub(" ", s)
    s = WS_RE.sub(" ", s).strip()
    return s
```


src/normalizer/rules/normalize_rules.py

```python
import csv, json
from .token_maps import *
from ..utils_text import normalize_text

def apply_alias_map(name: str, alias_csv: str) -> str | None:
    n = normalize_text(name)
    with open(alias_csv) as f:
        for row in csv.reader(f):
            alias, canonical = row
            if normalize_text(alias) == n:
                return canonical
    return None

def expand_abbrev(tokens: list[str], common_json: str) -> list[str]:
    maps = json.load(open(common_json))
    return [maps.get(t, t) for t in tokens]
```

Populate token_maps/*.csv with your curated alias dictionaries (WoS/InCites give you canonical names; you add common variants).

---

### Candidate generation (FAISS + fuzzy)

src/normalizer/candidates/faiss_index.py

```python
import faiss, numpy as np
from sentence_transformers import SentenceTransformer

class FaissSearcher:
    def __init__(self, names, model_name, index_path=None, normalize=True):
        self.names = names
        self.model = SentenceTransformer(model_name)
        self.normalize = normalize
        if index_path and Path(index_path).exists():
            self.index = faiss.read_index(str(index_path))
            self.embeds = np.load(str(Path(index_path).with_suffix(".ids.npy")))
        else:
            X = self.model.encode(names, normalize_embeddings=True)
            self.index = faiss.IndexFlatIP(X.shape[1])
            self.index.add(X)
            self.embeds = X  # keep in memory for serialization

    def search(self, query: str, k=50):
        q = self.model.encode([query], normalize_embeddings=True)
        D, I = self.index.search(q, k)
        return [(int(i), float(s)) for i, s in zip(I[0], D[0])]
```

src/normalizer/candidates/generator.py

```python
from rapidfuzz import process, fuzz

def gen_fuzzy(name: str, names: list[str], k=20):
    return process.extract(name, names, limit=k, scorer=fuzz.token_sort_ratio)

def gen_candidates(name: str, names: list[str], faiss_searcher: FaissSearcher, k_embed=50, k_fuzzy=20):
    fuzzy = gen_fuzzy(name, names, k=k_fuzzy)  # [(candidate, score0..100), ...]
    embed = [(names[i], s) for i, s in faiss_searcher.search(name, k=k_embed)]
    # de-duplicate by best score
    bag = {}
    for cand, s in fuzzy:
        bag[cand] = max(bag.get(cand, 0), 0.5 - (s/100))
    for cand, s in embed:
        bag[cand] = max(bag.get(cand, 0), bag.get(cand, 0) + 0.5 - s)
    return sorted(bag.items(), key=lambda x: x[1], reverse=True)

```

---

### Context features & reranker

rc/normalizer/ranking/context_features.py

```python
def ctx_score(entity_type: str, user_ctx: dict, cand_row: dict) -> float:
    """
    Example: for organizations, boost if user_ctx.country == cand_row.country
    for journals, boost if issn matches; for funders, match country/parent org.
    Return value in [0, 1].
    """
    s = 0.0
    if entity_type == "organizations":
        if user_ctx.get("country") and cand_row.get("country"):
            s += 1.0 if user_ctx["country"] == cand_row["country"] else 0.0
    if entity_type == "journals":
        if user_ctx.get("issn") and cand_row.get("issn"):
            s += 1.0 if user_ctx["issn"] == cand_row["issn"] else 0.0
    # ... extend rules as needed
    return min(s, 1.0)
```

src/normalizer/ranking/reranker.py

```python
from rapidfuzz import fuzz

def hybrid_score(user_input: str, cand_name: str, embed_score: float, entity_weights: dict) -> float:
    fuzzy = fuzz.token_sort_ratio(user_input, cand_name) / 100.0
    Œ±, Œ≤ = entity_weights["alpha_fuzzy"], entity_weights["beta_embed"]
    return Œ± - fuzzy + Œ≤ - embed_score

def final_score(user_input, cand_name, embed_score, ctx_s, entity_weights):
    base = hybrid_score(user_input, cand_name, embed_score, entity_weights)
    Œ≥ = entity_weights["gamma_ctx"]
    return base + Œ≥ - ctx_s
```

---

###  Catalogs (WoS/InCites master tables)

src/normalizer/stores/catalog.py

```python
import pandas as pd
from pathlib import Path

class Catalog:
    def __init__(self, path_csv: str, key_cols=("id","name")):
        self.df = pd.read_csv(path_csv)
        self.df["name_norm"] = self.df["name"].str.lower()
        self.names = self.df["name"].tolist()

    def row_by_name(self, name: str) -> dict | None:
        hit = self.df[self.df["name"] == name]
        return None if hit.empty else hit.iloc[0].to_dict()
```

---

### Entity normalizers

src/normalizer/entity_types/base.py

```python
from ..candidates.faiss_index import FaissSearcher
from ..candidates.generator import gen_candidates
from ..ranking.context_features import ctx_score
from ..ranking.reranker import final_score
from ..stores.catalog import Catalog
from ..config import CFG

class BaseNormalizer:
    def __init__(self, entity: str, catalog_path: str):
        self.entity = entity
        self.catalog = Catalog(catalog_path)
        self.searcher = FaissSearcher(self.catalog.names, CFG.model_name)

    def normalize(self, text: str, user_ctx: dict | None = None):
        user_ctx = user_ctx or {}
        w = CFG.weights[self.entity]
        cands = gen_candidates(text, self.catalog.names, self.searcher)
        best = None
        for cand_name, embed_mix in cands[:50]:
            row = self.catalog.row_by_name(cand_name)
            ctxs = ctx_score(self.entity, user_ctx, row)
            score = final_score(text, cand_name, embed_mix, ctxs, w)
            if not best or score > best["score"]:
                best = {"name": cand_name, "id": row.get("id"), "score": score, "row": row}
        return best if best and best["score"] >= w["threshold"] else {"name": None, "id": None, "score": best["score"] if best else 0.0}
```


src/normalizer/entity_types/journals.py

```python
from .base import BaseNormalizer
class JournalNormalizer(BaseNormalizer):
    def __init__(self, catalog_path="data/catalo gs/journals.csv"):
        super().__init__("journals", catalog_path)
Similarly implement organizations.py, countries.py, funders.py, topics.py (just pass entity key & path).
```

---

### Orchestrator

src/normalizer/pipeline.py

```python
from .entity_types.journals import JournalNormalizer
from .entity_types.organizations import OrganizationNormalizer
from .entity_types.countries import CountryNormalizer
from .entity_types.funders import FunderNormalizer
from .entity_types.topics import TopicNormalizer

class NormalizationPipeline:
    def __init__(self):
        self.journals = JournalNormalizer()
        self.orgs = OrganizationNormalizer()
        self.countries = CountryNormalizer()
        self.funders = FunderNormalizer()
        self.topics = TopicNormalizer()

    def normalize(self, entity_type: str, text: str, ctx: dict | None = None):
        n = getattr(self, {
            "journal":"journals","journals":"journals",
            "organization":"orgs","org":"orgs","organizations":"orgs",
            "country":"countries","countries":"countries",
            "funder":"funders","funders":"funders",
            "topic":"topics","topics":"topics",
        }[entity_type])
        return n.normalize(text, ctx or {})
```

---

### FastAPI service

src/api/schemas.py

```python
from pydantic import BaseModel
class NormalizeReq(BaseModel):
    entity_type: str
    text: str
    context: dict | None = None

class NormalizeResp(BaseModel):
    id: str | None
    name: str | None
    score: float
```

src/api/main.py

```python
from fastapi import FastAPI
from .schemas import NormalizeReq, NormalizeResp
from ..normalizer.pipeline import NormalizationPipeline

app = FastAPI(title="Local Entity Normalizer")
pipe = NormalizationPipeline()

@app.post("/normalize", response_model=NormalizeResp)
def normalize(req: NormalizeReq):
    out = pipe.normalize(req.entity_type, req.text, req.context)
    return NormalizeResp(id=out.get("id"), name=out.get("name"), score=out.get("score", 0.0))
```

Run:


```bash
uvicorn src.api.main:app --reload --host 0.0.0.0 --port 8000

cURL examples:

curl -X POST http://localhost:8000/normalize \
  -H "Content-Type: application/json" \
  -d '{"entity_type":"organizations","text":"MIT","context":{"country":"United States"}}'

CLI (batch)
```

src/cli/normalize.py

```python
import sys, csv, json
from normalizer.pipeline import NormalizationPipeline

if __name__ == "__main__":
    pipe = NormalizationPipeline()
    rdr = csv.DictReader(sys.stdin)
    wtr = csv.DictWriter(sys.stdout, fieldnames=["entity_type","input","id","name","score"])
    wtr.writeheader()
    for row in rdr:
        out = pipe.normalize(row["entity_type"], row["input"], json.loads(row.get("context","{}")))
        wtr.writerow({"entity_type": row["entity_type"], "input": row["input"],
                      "id": out.get("id"), "name": out.get("name"), "score": out.get("score", 0.0)})
```

Usage:

```bash
cat inputs.csv | python -m src.cli.normalize > outputs.csv
```

---

### Evaluation harness

src/normalizer/eval/metrics.py

```python
import pandas as pd

def top1_accuracy(df: pd.DataFrame):
    return (df["pred_id"] == df["gold_id"]).mean()

def mrr(df: pd.DataFrame):
    return df["reciprocal_rank"].mean()
```

src/normalizer/eval/evaluate.py

```python
# Expect data/eval/labeled_pairs.csv: input_name,entity_type,gold_id,context(json)
import json, pandas as pd
from ..pipeline import NormalizationPipeline

def run_eval():
    df = pd.read_csv("data/eval/labeled_pairs.csv")
    pipe = NormalizationPipeline()
    preds = []
    for _, r in df.iterrows():
        ctx = json.loads(r.get("context","{}"))
        out = pipe.normalize(r["entity_type"], r["input_name"], ctx)
        preds.append({"pred_id": out.get("id"), "pred_name": out.get("name"), "score": out.get("score",0.0)})
    out_df = pd.concat([df, pd.DataFrame(preds)], axis=1)
    print("Top-1 acc:", (out_df["pred_id"] == out_df["gold_id"]).mean())
    out_df.to_csv("data/eval/predictions.csv", index=False)

if __name__ == "__main__":
    run_eval()
```

---

### Data prep tips (WoS/InCites)

- Journals: include id, name, issn, eissn, subject_category, aliases.
- Organizations: include id, name, ROR/GRID, country, aliases, parent/child relations (CSV or graph).
- Funders: id, name, country, aliases, parent agency (e.g., EC‚ÜíERC).
- Countries: iso2, iso3, name, aliases (e.g., ‚ÄúUK‚Äù, ‚ÄúU.K.‚Äù, ‚ÄúUnited Kingdom‚Äù).
- Topics: canonical taxonomy (WoS Categories / Research Areas) + keywords & aliases.

---

### Quality jumps when you:

1. curate alias files
2. carry ISSN for journals
3. use country & field as context
4. add org hierarchy (ROR/GRID)
5. tune weights per entity in weights.yaml

---

### Performance & deployment

- Embeddings: BAAI/bge-small-en or gte-small ‚Üí CPU-friendly and accurate.
- Index: FAISS IndexFlatIP for simplicity; use HNSW if millions of entries.
- Cache: turn on Redis/SQLite for hot queries.
- Optional: Qdrant for persistent vector store; Neo4j to model org hierarchies and boost children‚Üîparent matches.

---

### Docker (minimal)

docker/Dockerfile

```bash
FROM python:3.11-slim
WORKDIR /app
COPY . .
RUN pip install -U pip && pip install -e .
EXPOSE 8000
CMD ["uvicorn", "src.api.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

---

### What you get

- Local, fast, LLM-free normalization with hybrid accuracy suitable for WoS/InCites integration.
- REST API + CLI + evaluation harness.
- Clean knobs to tune per entity (Œ±/Œ≤/Œ≥ & thresholds), plus context-aware reranking.

If you want, I can also share starter CSV schemas for each catalog and a weight-tuning notebook to maximize Top-1 on your labeled pairs.


---


##  A Concrete Local Implementation Plan 

Great üëç ‚Äî then here‚Äôs a concrete local implementation plan for your research entity normalization system (topics, journals, organizations, countries, funders) without relying on online LLM calls, while still aiming for high-quality, WoS/InCites-level matching:

---

### üîπ Recommended Approach

You need a hybrid normalization pipeline that combines:

1. Rule-based & dictionary matching ‚Üí fast, for exact/abbreviation lookups.
2. Embedding-based semantic similarity ‚Üí to capture typos, paraphrases, synonyms.
3. Fuzzy matching (string edit distance, phonetic codes) ‚Üí for robustness to spelling variants.
4. Context-aware reranking ‚Üí to ensure best match in ambiguous cases (e.g., "MIT" ‚Üí Massachusetts Institute of Technology, not Manukau Institute of Technology).

This is fully doable locally with modern open-source models.

---

### üîπ Candidate Models

- Sentence-transformers (local embeddings)
    - all-MiniLM-L6-v2 (fast, small, good general embeddings).
    - msmarco-distilbert-base-v3 (optimized for semantic search).
    - If you want academic-tuned embeddings, use allenai-specter2 (trained on academic papers, great for topics/journals/authors).
- Fuzzy & phonetic libraries
    - rapidfuzz (fast fuzzy string matching).
    - python-Levenshtein (edit distance).
    - metaphone / phonetics for phonetic similarity (good for names).
- Vector search
    - FAISS (local similarity search, scalable).
    - Qdrant if you want persistent storage + filtering (funders by country, journals by field, etc.).

---

### üîπ Framework Integration

- Elasticsearch / OpenSearch
    - Store canonical names + synonyms + metadata.
    - Use BM25 + embeddings hybrid search.
- FAISS / Qdrant
    - Fast semantic retrieval for candidate matches.
- Reranker (local model)
    - cross-encoder/ms-marco-MiniLM-L-6-v2 can rerank top-10 candidates.
- Optional Graph Layer
    - Neo4j for organizational hierarchies (subsidiaries, funder groups, etc.).


---

### üîπ Example Implementation (Python)


```python
from sentence_transformers import SentenceTransformer, util
import faiss
import pandas as pd
import rapidfuzz

# Load local model
model = SentenceTransformer("allenai-specter2")

# Example canonical dataset (WoS-like)
canonical_df = pd.DataFrame({
    "id": [1, 2, 3],
    "name": ["Massachusetts Institute of Technology", 
             "University of California, Berkeley",
             "National Institutes of Health"],
    "type": ["organization", "organization", "funder"]
})

# Build embeddings
embeddings = model.encode(canonical_df["name"].tolist(), normalize_embeddings=True)
index = faiss.IndexFlatIP(embeddings.shape[1])
index.add(embeddings)

def normalize_entity(user_input, top_k=5):
    # Encode user input
    query_vec = model.encode([user_input], normalize_embeddings=True)
    D, I = index.search(query_vec, top_k)
    
    candidates = canonical_df.iloc[I[0]]
    
    # Apply fuzzy boost
    candidates["fuzzy_score"] = candidates["name"].apply(
        lambda x: rapidfuzz.fuzz.partial_ratio(user_input, x)
    )
    
    # Rank by hybrid score
    candidates["hybrid_score"] = D[0] + candidates["fuzzy_score"]/100.0
    return candidates.sort_values("hybrid_score", ascending=False).head(1)

print(normalize_entity("MIT"))
print(normalize_entity("NIH"))

```

- ‚úÖ "MIT" ‚Üí Massachusetts Institute of Technology‚Ä®
- ‚úÖ "NIH" ‚Üí National Institutes of Health

---

### üîπ Why This Works

- Data security: Everything runs locally, no external LLM calls.
- Performance: Embeddings + FAISS make lookups very fast (<100ms per query).
- Cost saving: No API calls, just compute once.
- Accuracy: Combination of semantic + fuzzy + reranking = high recall & precision.
- Scalability: Works on millions of canonical entries (journals, funders, authors).

‚ö° Next step: I can design a full pipeline for each entity type (topic, journal, organization, country, funder), with specialized preprocessing (e.g., country ISO codes, journal ISSNs, funder hierarchy).

üëâ Do you want me to outline the per-entity normalization strategy (rules + embeddings + metadata) for each category, so you have a blueprint for WoS/InCites-level normalization?


---

## Per-entity Normalization Strategy


Perfect üöÄ ‚Äî let‚Äôs design a per-entity normalization strategy so your system can unify messy user input into WoS/InCites canonical forms.


### üîπ Entity Normalization Blueprint


1Ô∏è‚É£ Research Topics

- Canonical source: WoS Research Areas, InCites Subject Categories, MeSH, OECD taxonomy.
- Challenges: Synonyms, plural/singular, abbreviations, topic granularity.
- Strategy:
    - Preprocess: lowercase, lemmatize, strip stopwords (‚Äútheoretical physics‚Äù ‚Üí ‚Äútheoretical physic‚Äù).
    - Dictionary: synonyms (‚ÄúML‚Äù ‚Üí ‚ÄúMachine Learning‚Äù).
    - Embeddings: use allenai-specter2 (trained on academic text).
    - Context: match with closest WoS category cluster.

‚úÖ Example:
- Input: "comp bio" ‚Üí Output: "Computational Biology"


2Ô∏è‚É£ Journals

- Canonical source: WoS Core Collection (journal titles + ISSN + eISSN).
- Challenges: Abbreviations, multiple ISSNs, historical name changes.
- Strategy:
    - Preprocess: normalize punctuation, strip ‚ÄúJournal of‚Äù, match ISSN if provided.
    - Dictionary: official abbreviations (e.g., "JAMA" ‚Üí "Journal of the American Medical Association").
    - Embeddings: msmarco-distilbert-base-v3 or specter2 for semantic similarity.
    - Metadata: ISSN match > title similarity.

‚úÖ Example:
- Input: "PNAS" ‚Üí Output: "Proceedings of the National Academy of Sciences of the USA (PNAS)"


3Ô∏è‚É£ Organizations (Affiliations)

- Canonical source: WoS Organization-Enhanced, GRID/ROR.
- Challenges: Acronyms, name variants, campus/department names.
- Strategy:
    - Preprocess: remove department/lab suffixes.
    - Dictionary: known acronyms (‚ÄúMIT‚Äù, ‚ÄúUC Berkeley‚Äù).
    - Embeddings: all-MiniLM-L6-v2 (fast, general purpose).
    - Fuzzy: catch typos.
    - Graph: resolve to parent org if match is ambiguous.

‚úÖ Example:
- Input: "Harvard Med Sch" ‚Üí Output: "Harvard Medical School, Harvard University"


4Ô∏è‚É£ Countries

- Canonical source: ISO 3166, WoS country list.
- Challenges: Synonyms, political variants.
- Strategy:
    - Dictionary: map synonyms (‚ÄúUK‚Äù, ‚ÄúBritain‚Äù ‚Üí ‚ÄúUnited Kingdom‚Äù; ‚ÄúPRC‚Äù ‚Üí ‚ÄúChina‚Äù).
    - No embeddings needed (small set).
    - Fuzzy for misspellings.

‚úÖ Example:
- Input: "South Korea" ‚Üí Output: "Republic of Korea"


5Ô∏è‚É£ Funders

- Canonical source: WoS Funding Agencies, Crossref Funder Registry, GRID/ROR.
- Challenges: Acronyms, multiple branches (NIH institutes), government vs foundation.
- Strategy:
    - Preprocess: strip ‚Äúgrant from‚Äù, ‚Äúfunded by‚Äù.
    - Dictionary: acronym expansion (‚ÄúNSF‚Äù ‚Üí ‚ÄúNational Science Foundation‚Äù).
    - Embeddings: specter2 for semantic similarity.
    - Metadata: match hierarchy (e.g., "NIH/NCI" ‚Üí parent NIH, child NCI).

‚úÖ Example:
- Input: "NCI grant" ‚Üí Output: "National Cancer Institute (NCI), National Institutes of Health (NIH)"

---

### üîπ End-to-End Pipeline

1. Preprocess: Normalize casing, punctuation, remove noise words.
2. Dictionary Lookup: Acronyms, synonyms, historical names.
3. Embedding Search (FAISS/Qdrant): Retrieve top candidates.
4. Fuzzy Boost (RapidFuzz): Adjust scores for edit-distance matches.
5. Metadata Reranking: Prefer exact ISSN, ISO code, ROR ID, funder hierarchy.
6. Disambiguation: If >1 strong candidate, choose parent (e.g., NIH vs sub-institute).


---

### üîπ Example: Journal Normalization Code


```python
def normalize_journal(user_input, journal_df, index, model):
    # Step 1: Preprocess
    query = user_input.lower().replace(".", "").strip()
    
    # Step 2: Dictionary lookup
    if query in journal_abbrev_dict:
        return journal_abbrev_dict[query]
    
    # Step 3: Embedding similarity
    query_vec = model.encode([query], normalize_embeddings=True)
    D, I = index.search(query_vec, 5)
    candidates = journal_df.iloc[I[0]]
    
    # Step 4: Fuzzy score
    candidates["fuzzy_score"] = candidates["title"].apply(
        lambda x: rapidfuzz.fuzz.ratio(user_input, x)
    )
    
    # Step 5: Hybrid score
    candidates["hybrid_score"] = D[0] + candidates["fuzzy_score"]/100.0
    
    # Step 6: Rerank by ISSN priority
    best = candidates.sort_values("hybrid_score", ascending=False).iloc[0]
    return {"canonical": best["title"], "issn": best["issn"]}
```

‚úÖ This design ensures security, speed, accuracy, and cost savings ‚Äî no LLM calls needed.‚Ä®It mimics what WoS/InCites do internally (dictionary + hierarchy + algorithmic disambiguation).

---

## Architecture Diagram + Modular Code Structure


Awesome ‚Äî here‚Äôs a unified, modular, fully-local architecture for entity normalization (topics, journals, organizations, countries, funders), plus clean code skeletons you can drop into a repo.


### Architecture (at a glance)

```plaintext
User input
   ‚îÇ
   ‚ñº
[ Preprocess & Rules ]
  - unicode/case/punct normalize
  - alias/abbrev expansion
  - noise removal (dept/lab/‚Äúgrant from‚Äù)
   ‚îÇ
   ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ [ Exact/Dedup Lookup ]  (O(1) dict / hash)
   ‚îÇ
   ‚ñº
[ Candidate Generation (Hybrid) ]
  - FAISS dense search (embeddings)
  - RapidFuzz fuzzy search (edit distance, token-sort)
   ‚îÇ
   ‚ñº
[ Rerank (Hybrid Score) ]
  score = Œ±¬∑fuzzy + Œ≤¬∑cosine + Œ≥¬∑context
  - context signals (ISSN/ISO/ROR/parent-child)
  - optional cross-encoder reranker (local)
   ‚îÇ
   ‚ñº
[ Decision + Calibrated Confidence ]
  - top1 if score ‚â• threshold (per entity type)
  - otherwise return N best + ‚Äúneeds_review‚Äù
   ‚îÇ
   ‚ñº
[ Cache + Telemetry ]
  - LRU/Redis for hot queries
  - false-positive logging ‚Üí alias list growth

```

---

### Repo layout


```plaintext

entity-normalizer/
‚îú‚îÄ pyproject.toml
‚îú‚îÄ README.md
‚îú‚îÄ configs/
‚îÇ  ‚îú‚îÄ app.yaml                 # model paths, index paths, switches
‚îÇ  ‚îî‚îÄ weights.yaml             # Œ±/Œ≤/Œ≥ + thresholds per entity type
‚îú‚îÄ data/
‚îÇ  ‚îú‚îÄ catalogs/                # canonical master tables
‚îÇ  ‚îÇ  ‚îú‚îÄ journals.csv          # id,title,issn,eissn,field,parent_id,aliases
‚îÇ  ‚îÇ  ‚îú‚îÄ orgs.csv              # id,name,ror,grid,country,parent_id,aliases
‚îÇ  ‚îÇ  ‚îú‚îÄ funders.csv           # id,name,country,parent_id,aliases
‚îÇ  ‚îÇ  ‚îú‚îÄ countries.csv         # iso2,iso3,name,aliases
‚îÇ  ‚îÇ  ‚îî‚îÄ topics.csv            # id,name,keywords,aliases,parent_id
‚îÇ  ‚îú‚îÄ embeddings/
‚îÇ  ‚îÇ  ‚îî‚îÄ indexes/              # *.faiss + *.npy (ids) per entity
‚îÇ  ‚îî‚îÄ eval/
‚îÇ     ‚îî‚îÄ labeled_pairs.csv     # input,entity_type,context,gold_id
‚îú‚îÄ src/
‚îÇ  ‚îú‚îÄ normalizer/
‚îÇ  ‚îÇ  ‚îú‚îÄ __init__.py
‚îÇ  ‚îÇ  ‚îú‚îÄ config.py
‚îÇ  ‚îÇ  ‚îú‚îÄ text/
‚îÇ  ‚îÇ  ‚îÇ  ‚îú‚îÄ normalize.py       # unicode/lower/punct/stopword/lemmatize
‚îÇ  ‚îÇ  ‚îÇ  ‚îî‚îÄ rules.py           # alias expanders (abbr maps)
‚îÇ  ‚îÇ  ‚îú‚îÄ stores/
‚îÇ  ‚îÇ  ‚îÇ  ‚îú‚îÄ catalog.py         # load master tables
‚îÇ  ‚îÇ  ‚îÇ  ‚îú‚îÄ faiss_index.py     # build/load/search dense index
‚îÇ  ‚îÇ  ‚îÇ  ‚îî‚îÄ cache.py           # LRU/Redis/SQLite
‚îÇ  ‚îÇ  ‚îú‚îÄ candidates/
‚îÇ  ‚îÇ  ‚îÇ  ‚îú‚îÄ fuzzy.py           # rapidfuzz utilities
‚îÇ  ‚îÇ  ‚îÇ  ‚îî‚îÄ generator.py       # merge dense+fuzzy candidates
‚îÇ  ‚îÇ  ‚îú‚îÄ ranking/
‚îÇ  ‚îÇ  ‚îÇ  ‚îú‚îÄ context.py         # ISSN/ISO/ROR/parent boosts
‚îÇ  ‚îÇ  ‚îÇ  ‚îî‚îÄ rerank.py          # Œ±Œ≤Œ≥ scoring + thresholds
‚îÇ  ‚îÇ  ‚îú‚îÄ entity/
‚îÇ  ‚îÇ  ‚îÇ  ‚îú‚îÄ base.py
‚îÇ  ‚îÇ  ‚îÇ  ‚îú‚îÄ journals.py
‚îÇ  ‚îÇ  ‚îÇ  ‚îú‚îÄ organizations.py
‚îÇ  ‚îÇ  ‚îÇ  ‚îú‚îÄ countries.py
‚îÇ  ‚îÇ  ‚îÇ  ‚îú‚îÄ funders.py
‚îÇ  ‚îÇ  ‚îÇ  ‚îî‚îÄ topics.py
‚îÇ  ‚îÇ  ‚îî‚îÄ pipeline.py
‚îÇ  ‚îú‚îÄ api/
‚îÇ  ‚îÇ  ‚îú‚îÄ main.py               # FastAPI
‚îÇ  ‚îÇ  ‚îî‚îÄ schemas.py
‚îÇ  ‚îî‚îÄ cli/
‚îÇ     ‚îú‚îÄ build_index.py
‚îÇ     ‚îî‚îÄ normalize.py          # batch CSV ‚Üí CSV/JSON
‚îî‚îÄ tests/
   ‚îú‚îÄ test_text.py
   ‚îú‚îÄ test_candidates.py
   ‚îú‚îÄ test_ranking.py
   ‚îî‚îÄ test_entities.py
```

---

### Key configs

configs/app.yaml

```yaml
embeddings:
  model_name: BAAI/bge-small-en
  device: cpu
indexes:
  journals: data/embeddings/indexes/journals.faiss
  organizations: data/embeddings/indexes/orgs.faiss
  funders: data/embeddings/indexes/funders.faiss
  topics: data/embeddings/indexes/topics.faiss
  countries: data/embeddings/indexes/countries.faiss   # optional
catalogs:
  journals: data/catalogs/journals.csv
  organizations: data/catalogs/orgs.csv
  funders: data/catalogs/funders.csv
  topics: data/catalogs/topics.csv
  countries: data/catalogs/countries.csv
cache:
  enabled: true
  backend: "sqlite"          # or redis
  path: data/cache.sqlite
configs/weights.yaml

journals:       {alpha_fuzzy: 0.35, beta_embed: 0.55, gamma_ctx: 0.10, threshold: 0.63}
organizations:  {alpha_fuzzy: 0.30, beta_embed: 0.55, gamma_ctx: 0.15, threshold: 0.66}
funders:        {alpha_fuzzy: 0.30, beta_embed: 0.60, gamma_ctx: 0.10, threshold: 0.64}
countries:      {alpha_fuzzy: 0.60, beta_embed: 0.30, gamma_ctx: 0.10, threshold: 0.85}
topics:         {alpha_fuzzy: 0.25, beta_embed: 0.65, gamma_ctx: 0.10, threshold: 0.62}
```

---

### Code skeletons (drop-in)


src/normalizer/text/normalize.py

```python
import re, unicodedata

_PUNCT = re.compile(r"[^\w\s]")
_WS = re.compile(r"\s+")

def nfkd_ascii(s: str) -> str:
    return unicodedata.normalize("NFKD", s).encode("ascii","ignore").decode()

def basic_clean(s: str) -> str:
    s = nfkd_ascii(s.lower())
    s = _PUNCT.sub(" ", s)
    s = _WS.sub(" ", s).strip()
    return s

NOISE_ORG = ("department of","school of","faculty of","lab","laboratory","college of")
def strip_org_noise(s: str) -> str:
    t = s
    for n in NOISE_ORG:
        t = t.replace(n, " ")
    return _WS.sub(" ", t).strip()

```


src/normalizer/text/rules.py

```python
from .normalize import basic_clean

ALIAS_MAP = {
  # fast path exacts; extend with CSV loader
  "mit": "Massachusetts Institute of Technology",
  "uc berkeley": "University of California, Berkeley",
  "pnas": "Proceedings of the National Academy of Sciences of the United States of America",
  "nih": "National Institutes of Health",
  "nsf": "National Science Foundation",
  "uk": "United Kingdom",
}

def alias_expand(s: str) -> str | None:
    key = basic_clean(s)
    return ALIAS_MAP.get(key)

```

src/normalizer/stores/catalog.py

```python
import pandas as pd

class Catalog:
    def __init__(self, path: str, name_col="name"):
        self.df = pd.read_csv(path)
        self.df[name_col] = self.df[name_col].astype(str)
        self.name_col = name_col
        self.names = self.df[name_col].tolist()

    def by_name(self, name: str) -> dict | None:
        hit = self.df[self.df[self.name_col] == name]
        return None if hit.empty else hit.iloc[0].to_dict()

    def by_id(self, _id) -> dict | None:
        hit = self.df[self.df["id"] == _id]
        return None if hit.empty else hit.iloc[0].to_dict()
```

src/normalizer/stores/faiss_index.py

```python
import faiss, numpy as np
from sentence_transformers import SentenceTransformer

class DenseSearcher:
    def __init__(self, names: list[str], model_name: str, device="cpu"):
        self.model = SentenceTransformer(model_name, device=device)
        self.names = names
        X = self.model.encode(names, normalize_embeddings=True)
        self.index = faiss.IndexFlatIP(X.shape[1])
        self.index.add(X)

    def search(self, query: str, k=50):
        q = self.model.encode([query], normalize_embeddings=True)
        D, I = self.index.search(q, k)
        return [(int(i), float(s)) for i, s in zip(I[0], D[0])]
```

src/normalizer/candidates/fuzzy.py

```python
from rapidfuzz import process, fuzz

def fuzzy_topk(query: str, choices: list[str], k=20):
    return process.extract(query, choices, limit=k, scorer=fuzz.token_sort_ratio)
```


src/normalizer/candidates/generator.py

```python
def hybrid_candidates(query, names, dense, k_embed=50, k_fuzzy=20):
    # embed
    embed = [(names[i], s) for i, s in dense.search(query, k_embed)]
    # fuzzy
    from .fuzzy import fuzzy_topk
    fuzzy = [(n, sc/100.0) for n, sc, _ in fuzzy_topk(query, names, k_fuzzy)]
    # merge by max
    bag = {}
    for n, s in embed: bag[n] = max(bag.get(n, 0), 0.55*s)
    for n, s in fuzzy: bag[n] = max(bag.get(n, 0), bag.get(n, 0) + 0.45*s)
    return sorted(bag.items(), key=lambda x: x[1], reverse=True)
```

src/normalizer/ranking/context.py

```python
def ctx_score(entity: str, user_ctx: dict, cand_row: dict) -> float:
    s = 0.0
    if entity == "journals":
        if user_ctx.get("issn") and cand_row.get("issn"):
            s += 1.0 if user_ctx["issn"] == cand_row["issn"] else 0.0
    if entity == "organizations":
        if user_ctx.get("country") and cand_row.get("country"):
            s += 1.0 if user_ctx["country"] == cand_row["country"] else 0.0
    if entity == "funders":
        if user_ctx.get("country") and cand_row.get("country"):
            s += 1.0 if user_ctx["country"] == cand_row["country"] else 0.0
    if entity == "countries":
        if user_ctx.get("iso2") and cand_row.get("iso2"):
            s += 1.0 if user_ctx["iso2"].upper() == cand_row["iso2"].upper() else 0.0
    # topics: boost parent/children keywords overlap if you add it
    return min(s, 1.0)
```

src/normalizer/ranking/rerank.py

```python
from rapidfuzz import fuzz

def base_score(query: str, name: str, embed_mix: float, Œ±: float, Œ≤: float) -> float:
    fuzzy = fuzz.token_sort_ratio(query, name) / 100.0
    return Œ±*fuzzy + Œ≤*embed_mix

def final_score(query, name, embed_mix, ctx_s, weights):
    return base_score(query, name, embed_mix, weights["alpha_fuzzy"], weights["beta_embed"]) + \
           weights["gamma_ctx"]*ctx_s
```

src/normalizer/entity/base.py

```python
from ..stores.catalog import Catalog
from ..stores.faiss_index import DenseSearcher
from ..candidates.generator import hybrid_candidates
from ..ranking.context import ctx_score
from ..ranking.rerank import final_score
from ..text.normalize import basic_clean
from ..text.rules import alias_expand
from ..config import CFG

class BaseNormalizer:
    def __init__(self, entity_key: str, catalog_path: str):
        self.entity_key = entity_key
        self.catalog = Catalog(catalog_path)
        self.searcher = DenseSearcher(self.catalog.names, CFG.model_name, CFG.device)
        self.weights = CFG.weights[entity_key]

    def normalize(self, text: str, ctx: dict | None = None):
        ctx = ctx or {}
        # fast alias path
        alias = alias_expand(text)
        if alias:
            row = self.catalog.by_name(alias)
            if row:
                return {"id": row.get("id"), "name": row["name"], "score": 1.0, "source": "alias"}

        query = basic_clean(text)
        cands = hybrid_candidates(query, self.catalog.names, self.searcher)
        best = None
        for name, embed_mix in cands[:50]:
            row = self.catalog.by_name(name)
            cs = ctx_score(self.entity_key, ctx, row)
            score = final_score(query, name, embed_mix, cs, self.weights)
            if not best or score > best["score"]:
                best = {"id": row.get("id"), "name": name, "score": score, "row": row, "source": "hybrid"}
        if best and best["score"] >= self.weights["threshold"]:
            return {k: best[k] for k in ("id","name","score","source")}
        return {"id": None, "name": None, "score": best["score"] if best else 0.0, "source": "none"}
```


src/normalizer/entity/journals.py (others identical pattern)

```python
from .base import BaseNormalizer
from ..config import CFG

class JournalNormalizer(BaseNormalizer):
    def __init__(self):
        super().__init__("journals", CFG.catalogs["journals"])
src/normalizer/pipeline.py

from .entity.journals import JournalNormalizer
from .entity.organizations import OrganizationNormalizer
from .entity.countries import CountryNormalizer
from .entity.funders import FunderNormalizer
from .entity.topics import TopicNormalizer

class Pipeline:
    def __init__(self):
        self._map = {
          "journals": JournalNormalizer(),
          "organizations": OrganizationNormalizer(),
          "countries": CountryNormalizer(),
          "funders": FunderNormalizer(),
          "topics": TopicNormalizer(),
        }

    def normalize(self, entity_type: str, text: str, context: dict | None = None):
        n = self._map[entity_type]
        return n.normalize(text, context or {})
```

---

### Build FAISS indexes (one-time)


src/cli/build_index.py

```python
import pandas as pd, faiss, numpy as np
from sentence_transformers import SentenceTransformer
import argparse

def build(csv_path, name_col, out_path, model_name="BAAI/bge-small-en"):
    df = pd.read_csv(csv_path)
    names = df[name_col].astype(str).tolist()
    model = SentenceTransformer(model_name)
    X = model.encode(names, normalize_embeddings=True)
    index = faiss.IndexFlatIP(X.shape[1]); index.add(X)
    faiss.write_index(index, out_path)
    np.save(out_path.replace(".faiss",".ids.npy"), np.arange(len(names)))
    print("Saved", out_path)

if __name__ == "__main__":
    ap = argparse.ArgumentParser()
    ap.add_argument("--csv", required=True)
    ap.add_argument("--name_col", default="name")
    ap.add_argument("--out", required=True)
    ap.add_argument("--model", default="BAAI/bge-small-en")
    args = ap.parse_args()
    build(args.csv, args.name_col, args.out, args.model)
```

---

### FastAPI (local service)


src/api/schemas.py

```python
from pydantic import BaseModel
class NormalizeReq(BaseModel):
    entity_type: str
    text: str
    context: dict | None = None
class NormalizeResp(BaseModel):
    id: str | None
    name: str | None
    score: float
    source: str
```

src/api/main.py

```python
from fastapi import FastAPI
from .schemas import NormalizeReq, NormalizeResp
from ..normalizer.pipeline import Pipeline

app = FastAPI(title="Local Entity Normalizer")
pipe = Pipeline()

@app.post("/normalize", response_model=NormalizeResp)
def normalize(req: NormalizeReq):
    out = pipe.normalize(req.entity_type, req.text, req.context)
    return NormalizeResp(**out)
```

Run:

```bash
uvicorn src.api.main:app --host 0.0.0.0 --port 8000

CLI (batch)
```

src/cli/normalize.py

```python
import sys, csv, json
from normalizer.pipeline import Pipeline

pipe = Pipeline()
r = csv.DictReader(sys.stdin)
w = csv.DictWriter(sys.stdout, fieldnames=["entity_type","input","id","name","score"])
w.writeheader()
for row in r:
    ctx = json.loads(row.get("context","{}"))
    out = pipe.normalize(row["entity_type"], row["input"], ctx)
    w.writerow({"entity_type": row["entity_type"], "input": row["input"],
                "id": out["id"], "name": out["name"], "score": f'{out["score"]:.3f}'})
```

Usage:

```bash
cat inputs.csv | python -m src.cli.normalize > outputs.csv
```

---

### Data schema tips (per entity)

- journals.csv: id,title,issn,eissn,subject_category,parent_id,aliases
- orgs.csv: id,name,ror,grid,country,parent_id,aliases
- funders.csv: id,name,country,parent_id,aliases
- countries.csv: iso2,iso3,name,aliases
- topics.csv: id,name,keywords,parent_id,aliases

Put comma-separated aliases; during load, explode into a dict for exact hits.

---

### Quality levers (to reach WoS/InCites level)

- Curate alias tables continuously from false-positive logs.
- Prefer ISSN for journals; ISO2/ISO3 for countries; ROR/GRID for orgs.
- Tune Œ±/Œ≤/Œ≥ per entity using labeled pairs.
- Add parent/child boosts (e.g., ‚ÄúNCI‚Äù ‚Üí NIH).
- Optional local reranker: cross-encoder/ms-marco-MiniLM-L-6-v2 on top-10.

---

### Tests (examples)

- Abbrev ‚Üí canonical (MIT, PNAS, NIH, NSF, UK).
- Typos (Harvad Unversity ‚Üí Harvard University).
- Ambiguity with context (UCLA with country=US).
- Journal ISSN exact match beats title similarity.


---


## Generate a full list of Acronyms, Synonyms or Abbreviations to Canonical Name


Great question üëç ‚Äî this is actually one of the hardest but most critical steps in building a local name normalization system for research entities like organizations, departments, colleges, and funders.

There isn‚Äôt a single ready-made dataset that gives you all acronyms/synonyms/abbreviations ‚Üí canonical name mappings for academia/funders, but you can systematically generate and expand such a list by combining multiple strategies:


---

### üîπ Step 1. Start from authoritative sources (canonical names)

- Clarivate WoS / InCites: already have standardized names for institutions, funders, and journals.
- GRID / ROR (Research Organization Registry): structured database of research organizations, with aliases and location metadata.
- Crossref Funder Registry: has canonical funder names and some aliases.
- MAG / OpenAlex: contain standardized organizations with many known synonyms.
- ROR + GRID merged can give you a starting canonical list with IDs.


### üîπ Step 2. Automatically generate acronym/abbreviation candidates

For each canonical name:

- Acronym extraction:
    - Example: Massachusetts Institute of Technology ‚Üí MIT
    - National Institutes of Health ‚Üí NIH
    - Generate acronyms by taking capitalized initials.
- Common short forms:
    - Drop words like University, Institute, College, Laboratory.
    - University of California, Los Angeles ‚Üí UCLA
    - California Institute of Technology ‚Üí Caltech
- Country tags:
    - Oxford University (UK) vs Oxford College (Canada).
- Departmental variants:
    - Dept. of Computer Science, Stanford ‚Üí Stanford CS.


### üîπ Step 3. Mine synonyms from text data

- From paper metadata: collect affiliation strings from authors in WoS/OpenAlex/Scopus, cluster them, and align to canonical entities.
- From grants/funder acknowledgements: funders often appear with multiple spellings (NSF, National Science Foundation, NSF-USA).
- NER-based extraction: use local NER models (e.g., spaCy + custom entity ruler) to detect organization spans in free text.

### üîπ Step 4. Use embedding + clustering for alias discovery

- Encode all free-text affiliation strings with sentence-transformer embeddings (e.g., all-mpnet-base-v2 or domain-trained scibert).
- Cluster them (HDBSCAN, Faiss K-means).
- Match cluster centroids to canonical names.
- Collect variations within clusters as candidate synonyms.

### üîπ Step 5. Normalize with rules + fuzzy matching

- Normalize strings by:
    - Lowercasing
    - Removing punctuation
    - Expanding known stopwords (Univ ‚Üí University, Inst ‚Üí Institute, Dept ‚Üí Department)
    - Handling country/city suffixes
- Apply fuzzy string matching (rapidfuzz, fuzzywuzzy, or Elasticsearch trigram search).
- Keep mappings with high similarity scores (‚â•90%) or strong embedding match.


### üîπ Step 6. Human-in-the-loop curation

- Automatic generation will give you 70‚Äì80% good mappings.
- For accuracy (esp. enterprise use with WoS/InCites), you‚Äôll need curation dashboards:
    - Show suggested alias ‚Üí canonical mapping
    - Human approves/rejects
    - Update alias dictionary.


### üîπ Implementation Framework (local, no LLM calls)

- Databases:
    - Canonical registry (ROR/GRID/Funder Registry)
    - Alias dictionary (expandable via pipeline)
- Tools:
    - sentence-transformers for embeddings
    - rapidfuzz for fuzzy match
    - Elasticsearch/Qdrant for retrieval
    - spaCy for rule-based NER
- Pipeline:
    1. Input free-text entity name
    2. Normalize (rules)
    3. Search in alias dictionary
    4. If not found ‚Üí fuzzy + embedding search against canonical registry
    5. Return top candidate(s)

‚úÖ Answer to your question:

Yes, it‚Äôs a very good approach to build such a mapping locally. It is workable, but requires a bootstrapping step:
- Start from canonical registries (ROR, GRID, Crossref Funder)
- Expand aliases via rules + mining + embeddings
- Curate iteratively.


---


## A Concrete Pipeline


Perfect üëç Let‚Äôs design a concrete Python pipeline to auto-generate alias (acronym/synonym/abbreviation) mappings for organizations & funders from a canonical list (e.g., ROR, GRID, Crossref Funder Registry).


### üîπ Step 1. Setup canonical registry

You need a list of canonical entities first. Example (simplified):

```python
canonical_entities = [
    {"id": "grid.1234.1", "name": "Massachusetts Institute of Technology"},
    {"id": "grid.5678.1", "name": "Stanford University"},
    {"id": "grid.9876.1", "name": "California Institute of Technology"},
    {"id": "fndr.111", "name": "National Science Foundation"},
]
```

In practice, you‚Äôll load from ROR/GRID/Funder Registry JSON/CSV.


### üîπ Step 2. Generate rule-based aliases

- Acronyms (initial letters)
- Common abbreviations (drop words: University, Institute, College, Department)
- Lowercased + punctuation stripped

```python
import re

def generate_aliases(name: str):
    aliases = set()
    norm = re.sub(r'[^\w\s]', '', name)  # remove punctuation
    words = norm.split()
    
    # Base forms
    aliases.add(name)
    aliases.add(norm)
    aliases.add(" ".join(words).lower())
    
    # Acronym
    acronym = "".join([w[0] for w in words if w[0].isalpha()]).upper()
    if len(acronym) > 1:
        aliases.add(acronym)
    
    # Drop stopwords
    stopwords = {"university", "institute", "college", "department", "the"}
    shortened = " ".join([w for w in words if w.lower() not in stopwords])
    if shortened and shortened != name:
        aliases.add(shortened)
    
    return aliases
```


### üîπ Step 3. Build initial alias dictionary

```python
alias_dict = {}

for entity in canonical_entities:
    for alias in generate_aliases(entity["name"]):
        alias_dict[alias.lower()] = entity["id"]
Now you have a fast lookup table:‚Ä®"mit" ‚Üí grid.1234.1, "caltech" ‚Üí grid.9876.1, etc.
```

### üîπ Step 4. Expand aliases with embeddings + clustering

Use sentence-transformers to catch non-trivial synonyms (e.g., "Natl Sci Foundation" ‚Üí "National Science Foundation").

```python
from sentence_transformers import SentenceTransformer, util
import torch

model = SentenceTransformer("all-mpnet-base-v2")

canonical_names = [c["name"] for c in canonical_entities]
canonical_embs = model.encode(canonical_names, convert_to_tensor=True)

def find_best_match(query, top_k=3, threshold=0.75):
    query_emb = model.encode(query, convert_to_tensor=True)
    scores = util.cos_sim(query_emb, canonical_embs)[0]
    best_idx = torch.topk(scores, k=top_k).indices
    results = [(canonical_names[i], float(scores[i])) for i in best_idx]
    return [(name, score) for name, score in results if score >= threshold]
```

Example:

```python
print(find_best_match("Natl Sci Foundation"))
# [('National Science Foundation', 0.89)]
```

### üîπ Step 5. Fuzzy matching backup

For misspellings / OCR errors:

```python
from rapidfuzz import process

def fuzzy_match(query, choices, score_cutoff=85):
    match = process.extractOne(query, choices, score_cutoff=score_cutoff)
    return match  # (best_match, score, index)
```

Example:
```python
print(fuzzy_match("Standford Univ", canonical_names))
# ('Stanford University', 92, 1)
```

### üîπ Step 6. Pipeline wrapper


```python
def normalize_entity(query: str):
    q = query.lower().strip()
    
    # Direct alias lookup
    if q in alias_dict:
        return alias_dict[q]
    
    # Embedding match
    emb_matches = find_best_match(query)
    if emb_matches:
        return emb_matches[0][0]  # return canonical name
    
    # Fuzzy match
    fuzzy = fuzzy_match(query, canonical_names)
    if fuzzy:
        return fuzzy[0]
    
    return None
```

### üîπ Step 7. Human-in-the-loop expansion

- Save discovered aliases ‚Üí canonical mapping in a DB (Redis, SQLite, or Elasticsearch).
- Build a curation UI where curators approve new aliases.
- Update alias dictionary iteratively.


### ‚úÖ This gives you a local, high-quality name normalization engine:

- Canonical DB (ROR/GRID/Funder Registry)
- Rule-based alias generator
- Embedding-based similarity search
- Fuzzy backup
- Human curation loop


---

## Handle Department-level Sub-entities


Perfect ‚Äî extending your organization name normalization pipeline to handle department-level sub-entities (e.g., ‚ÄúDept. of Comp. Sci., MIT‚Äù ‚Üí ‚ÄúDepartment of Computer Science, Massachusetts Institute of Technology‚Äù) requires three main enhancements:

Let‚Äôs go through the architecture, data strategy, and implementation plan step by step üëá


### üß© 1. Extended Normalization Architecture

Your goal:
Handle 3 levels of entities consistently:
Organization ‚Üí Suborganization (School/College) ‚Üí Department/Lab.


‚úÖ Multi-level normalization pipeline

üèóÔ∏è Department-level Normalization Pipeline: Step-by-Step

| Stage                  | Description                                                                 | Example Input                        | Normalized Output                                                      |
|------------------------|-----------------------------------------------------------------------------|--------------------------------------|------------------------------------------------------------------------|
| 1. Preprocessing       | Lowercase, remove punctuation, expand known abbreviations, correct typos.   | "Dept. of EECS, MIT"                 | "department of eecs mit"                                               |
| 2. Entity Segmentation | Split text into organization and subentity parts using patterns or regex.    | "school of medicine, harvard university" | {org: "harvard university", subunit: "school of medicine"}             |
| 3. Canonical Matching  | Match both organization and subentity using hybrid fuzzy + embedding search. | ‚Äî                                    | {org_canonical: "Harvard University", subunit_canonical: "Harvard Medical School"} |
| 4. Hierarchical Resolution | Ensure subentity belongs to the correct parent org via canonical registry. | "Computer Science Dept., Harvard University" ‚Üí valid | OK                                                                     |
| 5. Alias Expansion     | Save new aliases automatically for future normalization.                     | "EECS Dept, MIT"                     | add alias for MIT EECS                                                 |


---

### üß† 2. Knowledge Base Design (Local Canonical Registry)

You‚Äôll need hierarchical data and alias mapping tables.

#### (a) Canonical tables

- organizations: id, canonical_name, country, type (university, company, etc.)
- subunits: id, org_id (FK), canonical_name, type (department, school, lab)
- aliases: id, entity_id, alias_name, entity_type (‚Äòorg‚Äô or ‚Äòsubunit‚Äô)

#### (b) Example

#### Example: Organization and Subunit Tables

**organizations.csv**

| org_id | org_name                                 |
|--------|------------------------------------------|
| 1      | Massachusetts Institute of Technology    |
| 2      | Harvard University                       |

**subunits.csv**

| subunit_id | org_id | subunit_name                                         |
|------------|--------|-----------------------------------------------------|
| 11         | 1      | Department of Electrical Engineering and Computer Science |
| 12         | 2      | Harvard Medical School                              |

**aliases.csv**

| alias_name                | entity_type | entity_id |
|---------------------------|-------------|-----------|
| Dept. of EECS, MIT        | subunit     | 11        |
| MIT EECS                  | subunit     | 11        |
| Harvard Med School        | subunit     | 12        |
| Massachusetts Institute of Technology | org         | 1        |
| Harvard University        | org         | 2        |

---

### üßÆ 3. Algorithm for Department-level Normalization


#### Step 1. Detect entity structure

Use regex or lightweight model (e.g., spaCy custom NER) to tag potential:
- ORG_NAME
- SUBUNIT (e.g., ‚Äúdepartment of‚Äù, ‚Äúschool of‚Äù, ‚Äúcollege of‚Äù, ‚Äúfaculty of‚Äù)

Example:
```python
import re

def segment_affiliation(text):
    patterns = [
        (r"(department|school|college|faculty|lab|centre|center) of [a-z\s]+", "SUBUNIT"),
    ]
    org_part = re.sub(patterns[0][0], "", text, flags=re.I).strip(", ")
    subunit = re.findall(patterns[0][0], text, flags=re.I)
    return org_part, subunit[0] if subunit else None
```

#### Step 2. Normalize each part

Use your existing hybrid name normalization module for both:

- org_part ‚Üí canonical org (via fuzzy + embedding search)
- subunit_part ‚Üí canonical subunit (within that org)


#### Step 3. Hierarchical constraint

Match subunit only within matched org‚Äôs known subunits to avoid cross-institution errors.

---

#### ‚öôÔ∏è 4. Implementation Framework

Recommended stack

| Component         | Tool / Model                                         | Purpose                                 |
|-------------------|-----------------------------------------------------|-----------------------------------------|
| Text preprocessing| `textacy`, `ftfy`, `unidecode`                      | Normalize and clean raw input text      |
| NER / segmentation| spaCy (custom model or entity ruler)                | Extract organization and subunit phrases|
| Embedding         | MiniLM-L6-v2 or all-MiniLM-L12-v2 (SentenceTransformers) | Encode organization and department names|
| Search            | FAISS or Qdrant                                      | Fast vector similarity search           |
| Fuzzy fallback    | RapidFuzz                                            | Handle abbreviations and typos          |
| Data store        | SQLite or PostgreSQL (with optional JSON cache)      | Store canonical registry and aliases    |

---

### üîÅ 5. Self-learning Alias Expansion


Every time a user input resolves successfully to a canonical entity:

- Save the raw input as a new alias in the registry
- Periodically retrain your local embedding index
  - ‚Üí This gives automatic improvement over time.

---

### üß∞ 6. Example Flow

```python
input = "Dept. of Comp. Sci., Univ. of Toronto"

# Step 1: Segment
org_text, subunit_text = segment_affiliation(input)

# Step 2: Normalize org
org_canon = normalize_org(org_text)

# Step 3: Normalize subunit (only under matched org)
subunit_canon = normalize_subunit(subunit_text, org_canon)

# Output
{
  "input": "Dept. of Comp. Sci., Univ. of Toronto",
  "org": "University of Toronto",
  "subunit": "Department of Computer Science"
}
```

---

### üß© 7. Advanced: Graph-based Extension

Once stable, you can represent org‚Äìsubunit‚Äìalias relationships as a graph (Neo4j or NetworkX):
```scss
(University of Toronto) ‚îÄ hasSubunit ‚îÄ> (Department of Computer Science)
```

This allows contextual reranking (e.g., prioritize departments from the same parent org).

---

### ‚úÖ Summary

| **Goal*-                        | **Approach*-                                               |
|----------------------------------|------------------------------------------------------------|
| Department-level normalization   | Hierarchical name registry + hybrid matching               |
| Offline + high-quality           | Sentence-transformer embeddings + FAISS + fuzzy matching   |
| Self-improving                   | Dynamically save new aliases as they are encountered       |
| Extendable                       | Easily add schools, faculties, labs, and other subunits    |
| Data source                      | ROR, GRID, and internal subunit expansion                  |

Would you like me to generate a Python implementation template (modules + FAISS + alias database + sample data) for this extended org/department normalization pipeline?‚Ä®It will be fully offline and ready to integrate with your current system.


---

## Implementation Template - Handle Department-level Sub-entities


Great ‚Äî below is a ready-to-drop-in Python implementation template for a fully local, hierarchical organization ‚Üí subunit (school/college) ‚Üí department/lab normalization pipeline. It includes:

- data schemas (SQLite)
- scripts to build canonical tables & FAISS indexes
- segmentation (regex + spaCy fallback)
- hybrid candidate generation (FAISS embeddings + RapidFuzz)
- hierarchical reranking & verification (subunit constrained to matched org)
- alias capture (self-learning)
- simple CLI and FastAPI examples

You can copy these files into a repo (suggested layout shown), tweak thresholds, add your canonical CSVs (ROR/GRID), and run locally ‚Äî no online LLM required.

---

### Repo layout (recommended)

```plaintext
org-dept-normalizer/
‚îú‚îÄ pyproject.toml / requirements.txt
‚îú‚îÄ configs.yml
‚îú‚îÄ data/
‚îÇ  ‚îú‚îÄ catalogs/
‚îÇ  ‚îÇ  ‚îú‚îÄ orgs.csv         # id,name,ror,grid,country,aliases
‚îÇ  ‚îÇ  ‚îî‚îÄ subunits.csv     # id,org_id,name,type,aliases
‚îÇ  ‚îî‚îÄ indexes/
‚îú‚îÄ src/
‚îÇ  ‚îú‚îÄ db/
‚îÇ  ‚îÇ  ‚îî‚îÄ schema.py
‚îÇ  ‚îú‚îÄ text/
‚îÇ  ‚îÇ  ‚îú‚îÄ normalize.py
‚îÇ  ‚îÇ  ‚îî‚îÄ segment.py
‚îÇ  ‚îú‚îÄ embedding/
‚îÇ  ‚îÇ  ‚îú‚îÄ build_indexes.py
‚îÇ  ‚îÇ  ‚îî‚îÄ faiss_searcher.py
‚îÇ  ‚îú‚îÄ candidates/
‚îÇ  ‚îÇ  ‚îî‚îÄ generator.py
‚îÇ  ‚îú‚îÄ ranking/
‚îÇ  ‚îÇ  ‚îî‚îÄ rerank.py
‚îÇ  ‚îú‚îÄ pipeline.py
‚îÇ  ‚îú‚îÄ cli.py
‚îÇ  ‚îî‚îÄ api.py
‚îî‚îÄ tests/
```

Install requirements (suggestion):

```bash
pip install sentence-transformers faiss-cpu rapidfuzz spacy fastapi uvicorn sqlalchemy aiosqlite
python -m spacy download en_core_web_sm
```

---

### 1. DB schema (SQLite) ‚Äî src/db/schema.py


```python
# src/db/schema.py

import sqlite3
from pathlib import Path

DB_PATH = Path("data/registry.db")

def init_db(db_path=DB_PATH):
    conn = sqlite3.connect(db_path)
    cur = conn.cursor()
    cur.execute("""
    CREATE TABLE IF NOT EXISTS orgs (
        id TEXT PRIMARY KEY,
        name TEXT NOT NULL,
        ror TEXT,
        grid TEXT,
        country TEXT
    )""")
    cur.execute("""
    CREATE TABLE IF NOT EXISTS subunits (
        id TEXT PRIMARY KEY,
        org_id TEXT NOT NULL,
        name TEXT NOT NULL,
        type TEXT,
        FOREIGN KEY(org_id) REFERENCES orgs(id)
    )""")
    cur.execute("""
    CREATE TABLE IF NOT EXISTS aliases (
        id INTEGER PRIMARY KEY AUTOINCREMENT,
        entity_type TEXT NOT NULL, -- 'org' or 'subunit'
        entity_id TEXT,
        alias TEXT NOT NULL UNIQUE,
        source TEXT
    )""")
    conn.commit()
    conn.close()

if __name__ == "__main__":
    init_db()
    print("DB initialized at", DB_PATH)

```

Load canonical CSVs into DB (you can write a small loader using pandas to insert rows).

---

### 2. Text normalization & segmentation ‚Äî src/text/normalize.py and src/text/segment.py


```python
# src/text/normalize.py

import re, unicodedata
_WS = re.compile(r"\s+")
_PUNCT = re.compile(r"[^\w\s]")

def nfkd_ascii(s: str) -> str:
    if not s:
        return s
    return unicodedata.normalize("NFKD", s).encode("ascii","ignore").decode()

def basic_clean(s: str) -> str:
    if not s:
        return ""
    s = nfkd_ascii(s).lower()
    s = _PUNCT.sub(" ", s)
    s = _WS.sub(" ", s).strip()
    return s
```

```python
# src/text/segment.py

import re
from typing import Tuple, Optional
from .normalize import basic_clean

# common subunit keywords
SUBUNIT_KEYWORDS = [
    "department", "dept", "school", "college", "faculty", "institute",
    "laboratory", "lab", "center", "centre", "division", "unit", "institute"
]

# regex to capture patterns like "Dept. of X, Org", "X Department, Org", "Org - Dept X"
PATTERNS = [
    re.compile(r"(?P<sub>.*?(?:department|dept|school|college|faculty|lab|laborator|center|centre|division).*?)[,;:-]\s*(?P<org>.+)$", re.I),
    re.compile(r"(?P<org>.+?)[,;:-]\s*(?P<sub>.*(?:department|dept|school|college|faculty|lab|centre|center).*)$", re.I),
    re.compile(r"(?P<sub>^(?:dept|department|school|college)\b.*)\s+of\s+(?P<org>.+)$", re.I),
]

def segment_affiliation(text: str) -> Tuple[Optional[str], Optional[str]]:
    if not text:
        return None, None
    s = text.strip()
    # try patterns
    for p in PATTERNS:
        m = p.search(s)
        if m:
            return basic_clean(m.group("org")), basic_clean(m.group("sub"))
    # fallback: naive split by comma; guess last token is org if it contains "university"/"institute"/"college"
    parts = [p.strip() for p in s.split(",") if p.strip()]
    if len(parts) >= 2:
        last = basic_clean(parts[-1])
        if any(k in last.lower() for k in ["university", "institute", "college", "school", "academy", "center", "centre"]):
            org = last
            sub = basic_clean(", ".join(parts[:-1]))
            return org, sub
    # no segmentation
    return basic_clean(s), None
```

You can improve segmentation with a small spaCy custom pattern matcher if needed.

---

### 3. Build FAISS indexes from DB ‚Äî src/embedding/build_indexes.py

```python
# src/embedding/build_indexes.py

import sqlite3
import numpy as np
import faiss
from sentence_transformers import SentenceTransformer
from pathlib import Path

DB = Path("data/registry.db")
OUT_DIR = Path("data/indexes")
OUT_DIR.mkdir(parents=True, exist_ok=True)
MODEL_NAME = "all-MiniLM-L6-v2"  # or domain model like specter2

def fetch_all(entity_table: str):
    conn = sqlite3.connect(DB)
    cur = conn.cursor()
    cur.execute(f"SELECT id, name FROM {entity_table}")
    rows = cur.fetchall()
    conn.close()
    return rows

def build_index(table_name: str, out_index_path: Path):
    rows = fetch_all(table_name)
    ids = [r[0] for r in rows]
    names = [r[1] for r in rows]
    model = SentenceTransformer(MODEL_NAME)
    X = model.encode(names, normalize_embeddings=True)
    dim = X.shape[1]
    index = faiss.IndexFlatIP(dim)
    index.add(X.astype("float32"))
    faiss.write_index(index, str(out_index_path))
    np.save(str(out_index_path.with_suffix(".ids.npy")), np.array(ids))
    print(f"Built {table_name} index: {out_index_path}, n={len(names)}")

if __name__ == "__main__":
    build_index("orgs", OUT_DIR / "orgs.faiss")
    build_index("subunits", OUT_DIR / "subunits.faiss")
```
---

### 4. FAISS searcher utility ‚Äî src/embedding/faiss_searcher.py

```python
# src/embedding/faiss_searcher.py

import faiss, numpy as np
from sentence_transformers import SentenceTransformer
from pathlib import Path

MODEL_NAME = "all-MiniLM-L6-v2"

class FaissSearcher:
    def __init__(self, index_path: str, model_name=MODEL_NAME, device="cpu"):
        self.index_path = Path(index_path)
        self.index = faiss.read_index(str(self.index_path))
        ids_np = np.load(str(self.index_path.with_suffix(".ids.npy")), allow_pickle=True)
        self.ids = ids_np.tolist()
        self.model = SentenceTransformer(model_name)

    def search(self, query: str, k=10):
        q = self.model.encode([query], normalize_embeddings=True)
        D, I = self.index.search(q.astype("float32"), k)
        res = []
        for score, idx in zip(D[0], I[0]):
            if idx < 0:
                continue
            res.append((self.ids[idx], float(score)))
        return res
```

---

### 5. Candidate generator (hybrid) ‚Äî src/candidates/generator.py

```python
# src/candidates/generator.py

from rapidfuzz import process, fuzz
from ..embedding.faiss_searcher import FaissSearcher
import sqlite3

DB_PATH = "data/registry.db"

def fuzzy_topk(query, choices, k=10):
    # choices is list of strings
    items = process.extract(query, choices, limit=k, scorer=fuzz.token_sort_ratio)
    return [(it[0], it[1]/100.0) for it in items]  # (name, score 0..1)

class CandidateGenerator:
    def __init__(self, org_index_path, subunit_index_path):
        self.org_searcher = FaissSearcher(org_index_path)
        self.sub_searcher = FaissSearcher(subunit_index_path)
        # load choice lists for fuzzy
        conn = sqlite3.connect(DB_PATH)
        self.org_choices = [r[0] for r in conn.execute("SELECT name FROM orgs").fetchall()]
        self.sub_choices = [r[0] for r in conn.execute("SELECT name FROM subunits").fetchall()]
        conn.close()

    def gen_org_candidates(self, query, k_embed=10, k_fuzzy=10):
        embed = self.org_searcher.search(query, k=k_embed)  # list of (id, score)
        fuzzy = fuzzy_topk(query, self.org_choices, k=k_fuzzy)
        # map fuzzy names -> ids via DB
        conn = sqlite3.connect(DB_PATH)
        cands = {}
        for name, s in fuzzy:
            row = conn.execute("SELECT id FROM orgs WHERE name = ?", (name,)).fetchone()
            if row:
                cands[row[0]] = max(cands.get(row[0], 0), 0.4 - s)
        for id_, score in embed:
            cands[id_] = max(cands.get(id_, 0), 0.6 - score)
        conn.close()
        # return sorted (id, score)
        return sorted(cands.items(), key=lambda x: x[1], reverse=True)

    def gen_subunit_candidates(self, query, org_id=None, k=20):
        # if org_id provided, restrict to subunits under that org
        embed = self.sub_searcher.search(query, k=k)
        # optionally filter by org
        if org_id:
            # filter embed matches by org_id via DB
            conn = sqlite3.connect(DB_PATH)
            ids = []
            for id_, score in embed:
                r = conn.execute("SELECT org_id FROM subunits WHERE id = ?", (id_,)).fetchone()
                if r and r[0] == org_id:
                    ids.append((id_, score))
            conn.close()
            return ids
        return embed
```

---

### 6. Reranker & hierarchical verification ‚Äî src/ranking/rerank.py

```python
# src/ranking/rerank.py

from rapidfuzz import fuzz
import sqlite3

DB_PATH = "data/registry.db"
WEIGHTS = {"alpha_fuzzy": 0.35, "beta_embed": 0.55, "gamma_ctx": 0.1, "threshold": 0.6}

def fuzzy_score_str(query, cand_name):
    return fuzz.token_sort_ratio(query, cand_name) / 100.0

def get_org_row(org_id):
    conn = sqlite3.connect(DB_PATH)
    r = conn.execute("SELECT - FROM orgs WHERE id = ?", (org_id,)).fetchone()
    conn.close()
    return r

def get_sub_row(sub_id):
    conn = sqlite3.connect(DB_PATH)
    r = conn.execute("SELECT - FROM subunits WHERE id = ?", (sub_id,)).fetchone()
    conn.close()
    return r

def final_score(query, cand_name, embed_score, ctx_score=0.0, weights=WEIGHTS):
    f = fuzzy_score_str(query, cand_name)
    return weights["alpha_fuzzy"] - f + weights["beta_embed"] - embed_score + weights["gamma_ctx"] - ctx_score

def verify_subunit_belongs(sub_id, org_id):
    conn = sqlite3.connect(DB_PATH)
    r = conn.execute("SELECT org_id FROM subunits WHERE id = ?", (sub_id,)).fetchone()
    conn.close()
    return bool(r and r[0] == org_id)
```

---

### 7. Pipeline orchestrator ‚Äî src/pipeline.py

```python
# src/pipeline.py

from src.text.segment import segment_affiliation
from src.candidates.generator import CandidateGenerator
from src.ranking.rerank import final_score, verify_subunit_belongs, get_org_row, get_sub_row
import sqlite3
from src.db.schema import DB_PATH

class NormalizerPipeline:
    def __init__(self, org_index="data/indexes/orgs.faiss", sub_index="data/indexes/subunits.faiss"):
        self.gen = CandidateGenerator(org_index, sub_index)

    def normalize_affiliation(self, raw_text, ctx: dict = None):
        ctx = ctx or {}
        org_q, sub_q = segment_affiliation(raw_text)
        # 1) quick alias lookup (exact)
        conn = sqlite3.connect(DB_PATH)
        a = conn.execute("SELECT entity_type, entity_id FROM aliases WHERE alias = ?", (org_q,)).fetchone()
        if a and a[0] == 'org':
            org_id = a[1]; org_name = conn.execute("SELECT name FROM orgs WHERE id = ?", (org_id,)).fetchone()[0]
            # try subunit
            sub_id, sub_name = None, None
            if sub_q:
                b = conn.execute("SELECT entity_id FROM aliases WHERE alias = ?", (sub_q,)).fetchone()
                if b:
                    sub_id = b[0]; sub_name = conn.execute("SELECT name FROM subunits WHERE id = ?", (sub_id,)).fetchone()[0]
            conn.close()
            return {"org_id": org_id, "org_name": org_name, "sub_id": sub_id, "sub_name": sub_name, "score": 1.0, "source":"alias"}
        conn.close()

        # 2) generate org candidates
        org_cands = self.gen.gen_org_candidates(org_q, k_embed=8, k_fuzzy=8)  # [(id, score)]
        # evaluate top N
        best_org = None
        for oid, embed_score in org_cands[:10]:
            # fetch full name
            conn = sqlite3.connect(DB_PATH)
            row = conn.execute("SELECT name FROM orgs WHERE id = ?", (oid,)).fetchone()
            conn.close()
            if not row: continue
            cand_name = row[0]
            fs = final_score(org_q, cand_name, embed_score)
            if not best_org or fs > best_org["score"]:
                best_org = {"id": oid, "name": cand_name, "score": fs}
        if not best_org or best_org["score"] < 0.55:
            # low confidence; return top candidates for review
            return {"org_candidates": org_cands[:5], "score": best_org["score"] if best_org else 0.0, "source":"candidates"}

        # 3) subunit normalization (restricted to org)
        sub_res = {"sub_id": None, "sub_name": None, "sub_score": None}
        if sub_q:
            sub_cands = self.gen.gen_subunit_candidates(sub_q, org_id=best_org["id"], k=10)
            # rank by embed score + fuzzy
            best_sub = None
            for sid, emb_score in sub_cands:
                conn = sqlite3.connect(DB_PATH)
                sub_row = conn.execute("SELECT name FROM subunits WHERE id = ?", (sid,)).fetchone()
                conn.close()
                if not sub_row: continue
                sname = sub_row[0]
                sc = final_score(sub_q, sname, emb_score)
                if not best_sub or sc > best_sub["score"]:
                    best_sub = {"id": sid, "name": sname, "score": sc}
            if best_sub and best_sub["score"] >= 0.5:
                sub_res = {"sub_id": best_sub["id"], "sub_name": best_sub["name"], "sub_score": best_sub["score"]}
            else:
                sub_res = {"sub_id": None, "sub_name": None, "sub_score": best_sub["score"] if best_sub else 0.0}

        # 4) save successful alias mapping for future (self-learning)
        if best_org and best_org["score"] >= 0.75:
            # store alias raw org_q -> org id
            conn = sqlite3.connect(DB_PATH)
            try:
                conn.execute("INSERT OR IGNORE INTO aliases (entity_type, entity_id, alias, source) VALUES (?,?,?,?)",
                             ("org", best_org["id"], org_q, "auto"))
                if sub_res.get("sub_id"):
                    conn.execute("INSERT OR IGNORE INTO aliases (entity_type, entity_id, alias, source) VALUES (?,?,?,?)",
                                 ("subunit", sub_res["sub_id"], sub_q, "auto"))
                conn.commit()
            finally:
                conn.close()

        return {
            "org_id": best_org["id"], "org_name": best_org["name"], "org_score": best_org["score"],
            "sub_id": sub_res["sub_id"], "sub_name": sub_res["sub_name"], "sub_score": sub_res["sub_score"],
            "source": "hybrid"
        }
```

---

### 8. CLI example ‚Äî src/cli.py

```python
# src/cli.py

import csv, sys, json
from src.pipeline import NormalizerPipeline

def main():
    pipe = NormalizerPipeline(org_index="data/indexes/orgs.faiss", sub_index="data/indexes/subunits.faiss")
    rdr = csv.DictReader(sys.stdin)
    wtr = csv.DictWriter(sys.stdout, fieldnames=["input","org_id","org_name","org_score","sub_id","sub_name","sub_score","source"])
    wtr.writeheader()
    for r in rdr:
        out = pipe.normalize_affiliation(r["input"], json.loads(r.get("context","{}")))
        wtr.writerow({
            "input": r["input"],
            "org_id": out.get("org_id"),
            "org_name": out.get("org_name"),
            "org_score": out.get("org_score"),
            "sub_id": out.get("sub_id"),
            "sub_name": out.get("sub_name"),
            "sub_score": out.get("sub_score"),
            "source": out.get("source")
        })

if __name__ == "__main__":
    main()
```

Usage:
```shell
cat inputs.csv | python -m src.cli > outputs.csv
# where inputs.csv has column "input"
```
---

### 9.  FastAPI demo ‚Äî src/api.py

```python
# src/api.py
from fastapi import FastAPI
from pydantic import BaseModel
from src.pipeline import NormalizerPipeline

app = FastAPI()
pipe = NormalizerPipeline(org_index="data/indexes/orgs.faiss", sub_index="data/indexes/subunits.faiss")

class Req(BaseModel):
    text: str
    context: dict = None

@app.post("/normalize")
def normalize(req: Req):
    return pipe.normalize_affiliation(req.text, req.context or {})
```

Run:

```shell
uvicorn src.api:app --reload --port 8000
```

---

### 10.  Sample records & initial data

- Put your canonical orgs.csv & subunits.csv in data/catalogs/ with columns:
    - orgs.csv: id,name,ror,grid,country,aliases (aliases comma-separated)
    - subunits.csv: id,org_id,name,type,aliases
- Use src/db/schema.py to initialize DB, then load CSVs into DB (small loader script).
- Then run src/embedding/build_indexes.py to create FAISS indexes.


---

### 11. Tuning & best practices

- Thresholds: tune best_org["score"] thresholds (0.55 for candidates, 0.75 for auto alias insert) against labeled dev data.
- Embedding model: all-MiniLM-L6-v2 is fast; for academic text, consider allenai-specter2 or scibert variants for better performance on subunit names.
- Alias DB: keep source column (auto, manual, ror, grid) so you can audit and prioritize manual overrides.
- Human review UI: build a simple UI to review low-confidence matches; approved mappings get inserted into aliases.
- Rebuild indexes: periodically rebuild FAISS indexes after alias additions (or add incremental indexing strategy).
- Context signals: use context (country, city, email domain) to break ties (if you see @mit.edu, boost MIT).
- Department/Unit patterns: expand regex for abbreviations like EECS ‚Üí mapping to full subunit; maintain a department abbreviations dictionary.
- Logging: log ambiguous inputs & top candidates to gather labeled pairs for evaluation and training.

---

### 12.  Evaluation harness

- Keep data/eval/labeled_pairs.csv with columns: input,org_id_gold,subunit_id_gold,context
- Compute top-1 accuracy for org and subunit separately.
- Iterate weight tuning (alpha/beta/gamma) to maximize top-1.

---

### 13.   Scaling notes

- For large catalogs (100k+ subunits): use FAISS HNSW, or Qdrant for persistence + filters.
- Use Redis for alias/cache lookups to reduce DB hits.
- For heavy throughput, run model embedding server or use batch encoding.

---

### Final notes & next steps

This template gives you a fully local pipeline to segment affiliation strings, match organizations and subunits, enforce hierarchical constraints, and continuously expand alias dictionaries. Next steps I can help with (pick any):

- Provide a loader script to import ROR/GRID CSVs into the SQLite schema.
- Create a small web UI (Flask/Streamlit) for curators to approve aliases and inspect low-confidence matches.
- Add a batch index updater that incrementally adds new alias embeddings into FAISS.
- Provide a tuning notebook (Jupyter) to evaluate thresholds and model choices on a labeled set.


---

## Loader Script 


Perfect üëç ‚Äî here‚Äôs the loader script that extends the previous normalization pipeline to include department-level entities under institutions.

This script loads data from multiple sources (CSV/JSON/SQL), cleans names, expands known acronyms, generates embeddings, and builds hierarchical normalization (Institution ‚Üí Department).

---

### üß† File: load_and_normalize_departments.py

```python

import pandas as pd
import re
import json
from sentence_transformers import SentenceTransformer
from fuzzywuzzy import fuzz
import faiss
import numpy as np
from tqdm import tqdm

# -----------------------------
# 1Ô∏è‚É£ Load source data
# -----------------------------
def load_data(institution_csv, department_csv, funder_csv=None):
    institutions = pd.read_csv(institution_csv)
    departments = pd.read_csv(department_csv)
    if funder_csv:
        funders = pd.read_csv(funder_csv)
    else:
        funders = pd.DataFrame(columns=["funder_id", "funder_name"])

    return institutions, departments, funders


# -----------------------------
# 2Ô∏è‚É£ Preprocessing & normalization
# -----------------------------
def normalize_text(text: str) -> str:
    text = str(text).strip().lower()
    text = re.sub(r'[^a-z0-9&.,\s\-()]', '', text)
    text = re.sub(r'\s+', ' ', text)
    return text


def clean_dataframe(df, col_name):
    df[col_name] = df[col_name].apply(normalize_text)
    df.drop_duplicates(subset=[col_name], inplace=True)
    df.reset_index(drop=True, inplace=True)
    return df


# -----------------------------
# 3Ô∏è‚É£ Acronym / synonym expansion
# -----------------------------
def build_acronym_map(df, name_col):
    acronyms = {}
    for name in df[name_col]:
        tokens = re.findall(r'\b[A-Z]{2,}\b', name.upper())
        for token in tokens:
            if token not in acronyms:
                acronyms[token] = name
    return acronyms


# -----------------------------
# 4Ô∏è‚É£ Embedding model setup
# -----------------------------
def embed_names(df, col_name, model):
    embeddings = model.encode(df[col_name].tolist(), normalize_embeddings=True)
    return np.array(embeddings, dtype=np.float32)


# -----------------------------
# 5Ô∏è‚É£ Build FAISS index
# -----------------------------
def build_faiss_index(embeddings):
    dim = embeddings.shape[1]
    index = faiss.IndexFlatIP(dim)
    index.add(embeddings)
    return index


# -----------------------------
# 6Ô∏è‚É£ Hierarchical matching
# -----------------------------
def match_department_to_institution(dept_name, dept_institution, inst_index, inst_df, inst_embs, model, threshold=0.75):
    dept_inst_clean = normalize_text(dept_institution)
    dept_name_clean = normalize_text(dept_name)
    dept_emb = model.encode([f"{dept_inst_clean} {dept_name_clean}"], normalize_embeddings=True)
    scores, ids = inst_index.search(dept_emb, k=1)
    best_match_score = float(scores[0][0])
    best_match_name = inst_df.iloc[int(ids[0][0])]['institution_name']
    if best_match_score >= threshold:
        return best_match_name, best_match_score
    return None, best_match_score


# -----------------------------
# 7Ô∏è‚É£ Main loader pipeline
# -----------------------------
def main_pipeline(inst_csv, dept_csv, fund_csv=None, output_dir="./normalized"):
    print("üöÄ Loading data...")
    inst_df, dept_df, fund_df = load_data(inst_csv, dept_csv, fund_csv)

    print("üßπ Cleaning text...")
    inst_df = clean_dataframe(inst_df, "institution_name")
    dept_df = clean_dataframe(dept_df, "department_name")
    fund_df = clean_dataframe(fund_df, "funder_name")

    print("üî† Building acronym maps...")
    acronym_map = {
        "institutions": build_acronym_map(inst_df, "institution_name"),
        "departments": build_acronym_map(dept_df, "department_name"),
        "funders": build_acronym_map(fund_df, "funder_name")
    }

    print("üß© Loading local embedding model...")
    model = SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2")

    print("üìä Embedding institutions...")
    inst_embeddings = embed_names(inst_df, "institution_name", model)
    inst_index = build_faiss_index(inst_embeddings)

    print("üè´ Linking departments to parent institutions...")
    dept_links = []
    for _, row in tqdm(dept_df.iterrows(), total=len(dept_df)):
        dept_name = row["department_name"]
        dept_institution = row.get("institution_name", "")
        matched_inst, score = match_department_to_institution(
            dept_name, dept_institution, inst_index, inst_df, inst_embeddings, model
        )
        dept_links.append({
            "department_name": dept_name,
            "parent_institution": matched_inst,
            "match_score": score
        })
    dept_links_df = pd.DataFrame(dept_links)

    print("üíæ Saving output...")
    inst_df.to_csv(f"{output_dir}/institutions_clean.csv", index=False)
    dept_df.to_csv(f"{output_dir}/departments_clean.csv", index=False)
    fund_df.to_csv(f"{output_dir}/funders_clean.csv", index=False)
    dept_links_df.to_csv(f"{output_dir}/department_institution_links.csv", index=False)

    with open(f"{output_dir}/acronym_maps.json", "w") as f:
        json.dump(acronym_map, f, indent=2)

    print("‚úÖ Done! All normalized entities saved.")
    return inst_df, dept_links_df, acronym_map


if __name__ == "__main__":
    main_pipeline(
        inst_csv="./data/institutions.csv",
        dept_csv="./data/departments.csv",
        fund_csv="./data/funders.csv",
        output_dir="./normalized"
    )

```

---

### üß© What This Script Does

1. Loads and cleans institution, department, and funder data.
2. Expands acronyms and normalizes text.
3. Embeds all names with a local model (MiniLM-L6-v2 ‚Äî fast, small).
4. Builds FAISS index for institutional names.
5. Matches each department to its likely parent institution based on embeddings.
6. Outputs cleaned CSV + JSON acronym map + department‚Äìinstitution links.

---

### ‚öôÔ∏è Future Extensions

You can easily extend it to:
- Add graph-based linking (Neo4j: (:Department)-[:BELONGS_TO]->(:Institution)),
- Add fuzzy/semantic hybrid scoring (e.g., combine Levenshtein + embedding cosine),
- Handle multi-country normalization by adding a country column to embeddings,
- Integrate local reranking LLM later for ambiguous cases.


---

## Web UI (Streamlit) for Curators


Excellent ‚Äî you‚Äôre moving toward a hybrid normalization + human-in-the-loop curation platform, which is the right design for production quality in research entity matching (institutions, departments, funders).
Below is a Streamlit-based curation UI built on top of the normalization pipeline you already have.‚Ä®It lets curators review, confirm, edit, or override automatically matched results (e.g., department ‚Üí institution).

---

### üß† Overview

Components:
1. Backend pipeline (you already have): does automatic normalization + FAISS matching.
2. Web UI (Streamlit):
    - Loads suggested matches.
    - Allows manual search + correction.
    - Saves curator decisions to a clean ‚Äúgold‚Äù CSV/DB.

---

###üì¶ File: curation_app.py

```python
import streamlit as st
import pandas as pd
from sentence_transformers import SentenceTransformer
import faiss
import numpy as np
from fuzzywuzzy import fuzz
import os

# ---------------------------
# Load data & models
# ---------------------------
@st.cache_resource
def load_model():
    return SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2")

@st.cache_data
def load_data(institution_path, department_path, match_path=None):
    inst_df = pd.read_csv(institution_path)
    dept_df = pd.read_csv(department_path)
    matches = pd.read_csv(match_path) if match_path and os.path.exists(match_path) else None
    return inst_df, dept_df, matches


@st.cache_resource
def build_faiss_index(df, model):
    embeddings = model.encode(df["institution_name"].tolist(), normalize_embeddings=True)
    dim = embeddings.shape[1]
    index = faiss.IndexFlatIP(dim)
    index.add(np.array(embeddings, dtype=np.float32))
    return index, embeddings


# ---------------------------
# Semantic + fuzzy matching
# ---------------------------
def suggest_institutions(query, model, inst_df, index, embeddings, k=5):
    q_emb = model.encode([query], normalize_embeddings=True)
    scores, ids = index.search(q_emb, k=k)
    results = []
    for score, idx in zip(scores[0], ids[0]):
        if idx < len(inst_df):
            name = inst_df.iloc[idx]["institution_name"]
            results.append({
                "institution_name": name,
                "semantic_score": float(score),
                "fuzzy_score": fuzz.token_sort_ratio(query.lower(), name.lower()) / 100.0
            })
    df = pd.DataFrame(results)
    df["combined_score"] = df[["semantic_score", "fuzzy_score"]].mean(axis=1)
    return df.sort_values("combined_score", ascending=False).head(k)


# ---------------------------
# Streamlit UI
# ---------------------------
def app():
    st.set_page_config(page_title="Research Entity Normalization Curation UI", layout="wide")
    st.title("üèõÔ∏è Research Entity Normalization ‚Äî Curator Dashboard")
    st.caption("Review and approve department ‚Üí institution mappings.")

    inst_path = st.sidebar.text_input("Institutions CSV", "./normalized/institutions_clean.csv")
    dept_path = st.sidebar.text_input("Departments CSV", "./normalized/departments_clean.csv")
    match_path = st.sidebar.text_input("Existing Matches CSV", "./normalized/department_institution_links.csv")

    inst_df, dept_df, matches = load_data(inst_path, dept_path, match_path)
    model = load_model()
    index, inst_embs = build_faiss_index(inst_df, model)

    # Pick department to review
    st.subheader("üîç Select Department for Review")
    dept_name = st.selectbox("Department", dept_df["department_name"].tolist())

    # Suggested institution
    auto_match = None
    if matches is not None and dept_name in matches["department_name"].values:
        auto_match = matches.loc[matches["department_name"] == dept_name, "parent_institution"].values[0]

    st.write(f"**Auto-suggested parent institution:*- `{auto_match}`" if auto_match else "No auto-match found.")

    # Manual override
    query = st.text_input("Search institution manually", dept_name)
    if st.button("üîé Search"):
        results = suggest_institutions(query, model, inst_df, index, inst_embs)
        st.dataframe(results, use_container_width=True)
        selected = st.selectbox("Select correct match", results["institution_name"].tolist())
        confirm = st.button("‚úÖ Confirm & Save Match")

        if confirm:
            new_entry = pd.DataFrame([{
                "department_name": dept_name,
                "parent_institution": selected,
                "curated_by": "curator_user",
            }])
            curated_path = "./normalized/curated_links.csv"
            if os.path.exists(curated_path):
                existing = pd.read_csv(curated_path)
                updated = pd.concat([existing, new_entry]).drop_duplicates(subset=["department_name"], keep="last")
            else:
                updated = new_entry
            updated.to_csv(curated_path, index=False)
            st.success(f"‚úÖ Saved mapping: {dept_name} ‚Üí {selected}")


if __name__ == "__main__":
    app()
```
---

### üß© What This Web App Does

- ‚úÖ Loads your normalized CSVs (institution, department, auto-matches).
- ‚úÖ Shows auto-suggested match per department.
- ‚úÖ Lets curator search, compare, override, and save curated match.
- ‚úÖ Combines semantic (embedding) + fuzzy (string) similarity.
- ‚úÖ Stores verified mappings in curated_links.csv.

---

### üß± Example Directory Layout

```kotlin
data/
  institutions.csv
  departments.csv
  funders.csv
normalized/
  institutions_clean.csv
  departments_clean.csv
  department_institution_links.csv
  acronym_maps.json
  curated_links.csv
curation_app.py
```

---

### üöÄ Run the Web App

```shell
streamlit run curation_app.py
Open in browser ‚Üí http://localhost:8501
```

---

### üîÆ Optional Future Enhancements

- ‚úÖ Add Neo4j backend (py2neo or neo4j-driver) for storing verified mappings.
- üß† Integrate feedback retraining (update FAISS with new curated pairs).
- üîç Add search filters (country, region, type).
- üë©‚Äçüíº Add user login and audit trail (for multiple curators).
- üìä Add dashboard summary (coverage, accuracy, unresolved entities).

Would you like me to extend this Streamlit UI next with a Neo4j graph backend ‚Äî so curators can visualize and confirm relationships (Institution ‚Üí Department ‚Üí Funder) interactively on a network graph?


---

## Batch Index Updater


Perfect ‚Äî you now have:

- ‚úÖ an offline normalization pipeline,
- ‚úÖ a curator Streamlit UI,‚Ä®and the next key piece you need is a Batch Index Updater ‚Äî a script that automatically refreshes your FAISS/alias index whenever:
- new canonical names or aliases are added,
- curators approve new mappings (e.g., department ‚Üí institution).

Below is a production-ready batch index updater module (update_index.py) that integrates with your local registry and FAISS vector store.

---
### üß© Purpose

The updater will:
1. Detect changes (new or updated canonical entities / aliases).
2. Recompute embeddings only for changed records.
3. Merge or rebuild FAISS index incrementally.
4. Save metadata (ID ‚Üí canonical name, alias list).
5. Optionally trigger reindexing of department-level subunits too.

### üìÇ File: update_index.py

```python
import os
import json
import faiss
import numpy as np
import pandas as pd
from sentence_transformers import SentenceTransformer
from datetime import datetime

# ----------------------------
# CONFIG
# ----------------------------
DATA_DIR = "./normalized"
INDEX_DIR = "./indexes"
MODEL_NAME = "sentence-transformers/all-MiniLM-L6-v2"
ENTITY_TYPES = ["institution", "department", "funder"]

# ----------------------------
# HELPERS
# ----------------------------
def ensure_dir(path):
    if not os.path.exists(path):
        os.makedirs(path)


def load_canonical_and_alias_data(entity_type):
    """Load canonical + alias data"""
    canonical_path = os.path.join(DATA_DIR, f"{entity_type}s_clean.csv")
    alias_path = os.path.join(DATA_DIR, f"{entity_type}_aliases.csv")

    if not os.path.exists(canonical_path):
        raise FileNotFoundError(f"Missing canonical file: {canonical_path}")

    canonical_df = pd.read_csv(canonical_path)
    alias_df = pd.read_csv(alias_path) if os.path.exists(alias_path) else pd.DataFrame(columns=["alias_name", "canonical_name"])

    # Merge canonical and aliases into one frame for embedding
    combined = []
    for _, row in canonical_df.iterrows():
        combined.append({"name": row["canonical_name"], "canonical_name": row["canonical_name"], "source": "canonical"})
    for _, row in alias_df.iterrows():
        combined.append({"name": row["alias_name"], "canonical_name": row["canonical_name"], "source": "alias"})
    df = pd.DataFrame(combined)
    return df


def save_faiss_index(entity_type, index, embeddings, df):
    ensure_dir(INDEX_DIR)
    index_path = os.path.join(INDEX_DIR, f"{entity_type}_index.faiss")
    meta_path = os.path.join(INDEX_DIR, f"{entity_type}_meta.json")

    faiss.write_index(index, index_path)
    df.to_json(meta_path, orient="records", indent=2)
    print(f"[‚úî] Saved FAISS index for {entity_type} ({len(df)} entries)")


# ----------------------------
# MAIN UPDATER
# ----------------------------
def rebuild_index_for_entity(entity_type, model):
    print(f"üîÑ Rebuilding FAISS index for: {entity_type}")
    df = load_canonical_and_alias_data(entity_type)
    names = df["name"].tolist()

    embeddings = model.encode(names, normalize_embeddings=True)
    dim = embeddings.shape[1]
    index = faiss.IndexFlatIP(dim)
    index.add(np.array(embeddings, dtype=np.float32))
    save_faiss_index(entity_type, index, embeddings, df)


def incremental_update(entity_type, model):
    """Incrementally add new aliases without full rebuild"""
    meta_path = os.path.join(INDEX_DIR, f"{entity_type}_meta.json")
    index_path = os.path.join(INDEX_DIR, f"{entity_type}_index.faiss")

    if not (os.path.exists(meta_path) and os.path.exists(index_path)):
        print(f"No existing index found for {entity_type}. Doing full rebuild.")
        return rebuild_index_for_entity(entity_type, model)

    df_existing = pd.read_json(meta_path)
    df_new = load_canonical_and_alias_data(entity_type)

    existing_names = set(df_existing["name"].tolist())
    new_entries = df_new[~df_new["name"].isin(existing_names)]

    if new_entries.empty:
        print(f"[‚úî] No new entries to update for {entity_type}.")
        return

    print(f"‚ûï Adding {len(new_entries)} new aliases for {entity_type}.")

    index = faiss.read_index(index_path)
    new_embeddings = model.encode(new_entries["name"].tolist(), normalize_embeddings=True)
    index.add(np.array(new_embeddings, dtype=np.float32))

    df_updated = pd.concat([df_existing, new_entries], ignore_index=True)
    save_faiss_index(entity_type, index, None, df_updated)


# ----------------------------
# CLI ENTRY
# ----------------------------
def main(mode="incremental"):
    ensure_dir(INDEX_DIR)
    model = SentenceTransformer(MODEL_NAME)

    for entity_type in ENTITY_TYPES:
        if mode == "full":
            rebuild_index_for_entity(entity_type, model)
        else:
            incremental_update(entity_type, model)

    print(f"\n‚úÖ Index update complete at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="Batch index updater for entity normalization")
    parser.add_argument("--mode", choices=["full", "incremental"], default="incremental", help="Rebuild or incrementally update")
    args = parser.parse_args()

    main(mode=args.mode)
```

---

### üß± Directory Layout

```pgsql
normalized/
  institutions_clean.csv
  institution_aliases.csv
  departments_clean.csv
  department_aliases.csv
  funders_clean.csv
  funder_aliases.csv
indexes/
  institution_index.faiss
  institution_meta.json
  department_index.faiss
  department_meta.json
update_index.py
```

---

### ‚öôÔ∏è Run Modes


üîÅ Incremental update (default)

Updates index only for new aliases or new canonical names:
```bash
python update_index.py
```

üß± Full rebuild

Regenerates embeddings and index from scratch:
```bash
python update_index.py --mode full
```

---

### üöÄ Integration Flow

1. Curator adds new alias in Streamlit ‚Üí saved in institution_aliases.csv or department_aliases.csv.
2. Run python update_index.py (nightly cron or after curation).
3. Updated FAISS and meta JSON become instantly available to your local normalization service.


---

### üß© Next optional upgrades

### üîÆ Optional Upgrades

| Feature                | Description                                                                                   |
|------------------------|-----------------------------------------------------------------------------------------------|
| Alias ingestion hook   | Automatically trigger the index updater after each curated alias is approved, ensuring the FAISS index stays current without manual intervention. |
| Index versioning       | Save versioned snapshots of each index (e.g., v1.0, v1.1) to allow easy rollback in case of errors or regressions. |
| Delta tracking         | Add a `last_updated` timestamp to each alias entry to efficiently detect and process only changed or new aliases during incremental updates. |
| Distributed updates    | Use distributed vector databases like Qdrant or Weaviate to support multi-node hosting and scalable, persistent index management. |


Would you like me to extend this with a background watcher (Python daemon or FastAPI endpoint) that automatically triggers incremental index updates whenever curated data changes, so you don‚Äôt need to run it manually?


---


##  Tuning Notebook (Jupyter) to Evaluate Thresholds and Model


Perfect ‚Äî this next step is critical to achieving high-quality normalization at scale.

You already have the pipeline, FAISS index, and curator UI ‚Äî now you need a Jupyter notebook for evaluating and tuning model performance and matching thresholds on a labeled dataset (ground truth pairs of input_name ‚Üí canonical_name).

Below is a complete evaluation and tuning notebook you can drop into your repo as notebooks/evaluate_name_matching.ipynb.

It supports:
- Comparing multiple embedding models
- Evaluating FAISS + fuzzy hybrid scores
- Finding the optimal threshold for precision‚Äìrecall tradeoff
- Generating evaluation reports and plots

---

### üìì evaluate_name_matching.ipynb


```python
# =========================================
# üîç Name Normalization Model Evaluation Notebook
# =========================================

# --- Setup
import pandas as pd
import numpy as np
from sentence_transformers import SentenceTransformer
from rapidfuzz import fuzz
from sklearn.metrics import precision_recall_fscore_support, roc_curve, auc
import faiss
import matplotlib.pyplot as plt
from tqdm.auto import tqdm

# --- Config
DATA_PATH = "../data/labeled_pairs.csv"  # columns: input_name, canonical_name, label (1/0)
MODEL_NAMES = [
    "sentence-transformers/all-MiniLM-L6-v2",
    "sentence-transformers/all-MiniLM-L12-v2",
    "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
]
TOP_K = 3

# --- Load data
df = pd.read_csv(DATA_PATH)
print(f"Loaded {len(df)} labeled examples")

# =========================================
# 1Ô∏è‚É£ Encode Canonical Names and Build FAISS Index
# =========================================
def build_faiss_index(model, canonical_names):
    embeddings = model.encode(canonical_names, normalize_embeddings=True)
    dim = embeddings.shape[1]
    index = faiss.IndexFlatIP(dim)
    index.add(np.array(embeddings, dtype=np.float32))
    return index, embeddings

# =========================================
# 2Ô∏è‚É£ Evaluate a model on labeled pairs
# =========================================
def evaluate_model(model_name, df, top_k=TOP_K):
    print(f"üîß Evaluating model: {model_name}")
    model = SentenceTransformer(model_name)
    canonical_names = df["canonical_name"].unique().tolist()

    # Build FAISS index for canonical names
    index, canonical_embs = build_faiss_index(model, canonical_names)
    name_to_idx = {name: i for i, name in enumerate(canonical_names)}

    y_true, y_score = [], []

    for _, row in tqdm(df.iterrows(), total=len(df)):
        query = row["input_name"]
        true_canon = row["canonical_name"]
        label = row["label"]

        q_emb = model.encode([query], normalize_embeddings=True)
        scores, ids = index.search(np.array(q_emb, dtype=np.float32), top_k)
        retrieved_names = [canonical_names[i] for i in ids[0]]
        max_score = float(scores[0][0])

        # Combine with fuzzy similarity for hybrid score
        fuzzy_score = max([fuzz.token_sort_ratio(query, name) for name in retrieved_names]) / 100.0
        hybrid_score = 0.5 - max_score + 0.5 - fuzzy_score

        y_true.append(label)
        y_score.append(hybrid_score)

    return np.array(y_true), np.array(y_score)

# =========================================
# 3Ô∏è‚É£ Threshold Tuning and Metrics
# =========================================
def tune_threshold(y_true, y_score):
    thresholds = np.linspace(0, 1, 101)
    results = []
    for t in thresholds:
        preds = (y_score >= t).astype(int)
        p, r, f1, _ = precision_recall_fscore_support(y_true, preds, average="binary")
        results.append((t, p, r, f1))
    df_tune = pd.DataFrame(results, columns=["threshold", "precision", "recall", "f1"])
    best = df_tune.loc[df_tune["f1"].idxmax()]
    return df_tune, best

# =========================================
# 4Ô∏è‚É£ ROC Curve Plot
# =========================================
def plot_roc(y_true, y_score, model_name):
    fpr, tpr, _ = roc_curve(y_true, y_score)
    roc_auc = auc(fpr, tpr)
    plt.figure(figsize=(5, 4))
    plt.plot(fpr, tpr, label=f"{model_name} (AUC={roc_auc:.3f})")
    plt.plot([0, 1], [0, 1], "k--")
    plt.xlabel("False Positive Rate")
    plt.ylabel("True Positive Rate")
    plt.title(f"ROC Curve: {model_name}")
    plt.legend()
    plt.show()
    return roc_auc

# =========================================
# 5Ô∏è‚É£ Run evaluation loop
# =========================================
results_summary = []

for model_name in MODEL_NAMES:
    y_true, y_score = evaluate_model(model_name, df)
    df_tune, best = tune_threshold(y_true, y_score)
    auc_score = plot_roc(y_true, y_score, model_name)
    results_summary.append({
        "model": model_name,
        "best_threshold": best["threshold"],
        "precision": best["precision"],
        "recall": best["recall"],
        "f1": best["f1"],
        "auc": auc_score
    })

summary_df = pd.DataFrame(results_summary)
summary_df.sort_values("f1", ascending=False, inplace=True)
summary_df
```

---

### üß© Example Output Table

| Model                                   | Best Threshold | Precision | Recall | F1   | AUC  |
|------------------------------------------|:--------------:|:---------:|:------:|:----:|:----:|
| all-MiniLM-L12-v2                       |     0.68       |   0.93    |  0.90  | 0.91 | 0.95 |
| all-MiniLM-L6-v2                        |     0.67       |   0.91    |  0.88  | 0.89 | 0.93 |
| paraphrase-multilingual-MiniLM-L12-v2   |     0.64       |   0.86    |  0.84  | 0.85 | 0.91 |


---

### üßÆ Key Benefits

- ‚úÖ Objectively compares embedding models
- ‚úÖ Tunes optimal matching threshold (for FAISS + fuzzy hybrid)
- ‚úÖ Produces precision‚Äìrecall‚ÄìF1 and ROC AUC metrics
- ‚úÖ Guides deployment threshold per entity type (e.g., institution_threshold=0.7)
- ‚úÖ Fully offline and reproducible

---

### üß± Recommended Directory Layout


```bash
project_root/
  normalized/
    institutions_clean.csv
  indexes/
  data/
    labeled_pairs.csv         # your ground truth pairs
  notebooks/
    evaluate_name_matching.ipynb
```

---

### üöÄ Next Steps

Once you‚Äôve identified the best model + threshold, update your normalization config:

```yaml
# normalization_config.yaml
model: "sentence-transformers/all-MiniLM-L12-v2"
match_thresholds:
  institution: 0.68
  department: 0.72
  funder: 0.65
```

Then your normalization service (or Streamlit app) can apply these tuned thresholds for confident auto-matches, routing low-confidence ones to curator review.

Would you like me to extend this notebook with cross-validation + confusion matrix visualization so you can statistically validate robustness across entity types (institution, department, funder)?

---



