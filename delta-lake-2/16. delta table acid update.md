## Delta Table ACID


âœ… Yes â€” Delta Lake fully supports ACID updates.
Thatâ€™s one of its biggest advantages over plain Parquet or CSV files.



### ğŸ“Œ What ACID Means in Delta Lake

ACID =
- 	Atomicity â†’ Either the entire transaction succeeds or nothing does.
- 	Consistency â†’ The table is always in a valid state before and after the operation.
- 	Isolation â†’ Concurrent reads and writes donâ€™t interfere; readers see a consistent snapshot.
- 	Durability â†’ Once a transaction commits, itâ€™s permanent and recoverable.

Delta Lake achieves this using transaction logs (_delta_log) + versioned data files.


---

### ğŸ§ª Examples of ACID Update in Delta Lake

1ï¸âƒ£ UPDATE statements (in-place updates)

You can use SQL directly:

```sql
UPDATE delta.`/delta/path/to/table`
SET status = 'inactive'
WHERE last_login < '2022-01-01';
```

Or PySpark API:

```python
from delta.tables import DeltaTable

delta_table = DeltaTable.forPath(spark, "/delta/path/to/table")
delta_table.update(
    condition="last_login < '2022-01-01'",
    set={"status": "'inactive'"}
)
```

ğŸ‘‰ Delta rewrites only the affected files atomically.


2ï¸âƒ£ DELETE


```sql
DELETE FROM delta.`/delta/path/to/table` WHERE is_deleted = true;
```

Or PySpark API:

```python
delta_table.delete("is_deleted = true")
```


3ï¸âƒ£ MERGE (UPSERT)

For inserting new rows and updating existing rows in a single ACID transaction:

 PySpark API:

```python
(
    delta_table.alias("t")
    .merge(updates_df.alias("s"), "t.id = s.id")
    .whenMatchedUpdateAll()
    .whenNotMatchedInsertAll()
    .execute()
)
```

This is fully atomic â€” no partial writes.


4ï¸âƒ£ Transaction Isolation & Versioning

Delta uses Snapshot Isolation:
- 	Readers always see a consistent snapshot of the table at the time their query started.
- 	Writers work on new versions; old versions remain available until vacuumed.

You can time travel to previous versions too:

```sql
SELECT * FROM delta.`/delta/path/to/table` VERSION AS OF 5;
```


5ï¸âƒ£ Concurrency Safety

Multiple jobs can read while another is updating â€” safely.

Multiple writers use optimistic concurrency control:
- 	If two transactions touch the same data files, the second one retries automatically.
- 	No locking needed like in RDBMS.

---

### âš¡ Why This Matters


ğŸ†š Delta Lake vs Parquet/CSV: ACID Operations


| Operation              | Parquet/CSV                | Delta Lake                |
|------------------------|----------------------------|---------------------------|
| UPDATE / DELETE        | âŒ Not supported directly   | âœ… Supported (ACID)        |
| MERGE / Upsert         | âŒ Complex & manual         | âœ… Native with ACID        |
| Concurrency            | âŒ Risk of corruption       | âœ… Snapshot isolation      |
| Rollback / Versioning  | âŒ None                     | âœ… Full version history    |


---

### ğŸ“Œ Key Internals

- 	Delta doesnâ€™t modify Parquet files in place.
- 	It writes new files with updated data, marks old files as removed in the transaction log, and commits atomically.
- 	This is what enables ACID semantics on top of a data lake.

---

### ğŸ“ Summary


âœ… Delta Lake supports full ACID operations, including:
- 	UPDATE
- 	DELETE
- 	MERGE (upsert)
- 	Transactions with isolation and durability
- 	Time travel & rollback

All of this happens without requiring a traditional database, just storage (e.g., S3, ADLS, HDFS) + Deltaâ€™s transaction log.



