
###  A. Architecture of ES Loader in Databrick Workflows


 Implementing the Elasticsearch (ES) loader as a separate common job in Databricks is a great design choice. This allows multiple data processing jobs to trigger the loader asynchronously with parameters, ensuring scalability, reusability, and parallel execution.

---

#### 1. Recommended Architecture

1. Common ES Loader Job

-	A standalone Databricks job that loads data into ES.
-	Accepts parameters such as:
    -	source_table (processed data location)
    -	data_source (to determine the ES index)
    -	es_nodes
    -	batch_id (optional for tracking)
    -	Can be triggered by different pipelines.

---

2. Data Processing Jobs

-	Each data pipeline processes and writes transformed data to a staging location (Delta/S3).
-	It triggers the ES loader job asynchronously with required parameters.

---

3. Parallel Execution

-	If a single processing job produces multiple datasets for different indices, it can trigger multiple asynchronous ES loader jobs.
-	Jobs can run in parallel for different data sources.

---


#### Implementation

1. Create a Common ES Loader Job in Databricks

Scala Spark Code for ES Loader Job
```scala
    import org.apache.spark.sql.{DataFrame, SparkSession}
    import org.elasticsearch.spark.sql._

    object ESLoaderJob {

    def loadToES(spark: SparkSession, sourceTable: String, dataSource: String, esNodes: String): Unit = {
        // Read processed data
        val df = spark.read.format("delta").load(sourceTable)

        // Define mapping of data sources to indices
        val indexMapping = Map(
        "sourceA" -> "index_a",
        "sourceB" -> "index_b",
        "sourceC" -> "index_c"
        )

        val esIndex = indexMapping.getOrElse(dataSource, "default_index")

        // ES Config
        val esConfig = Map(
        "es.nodes" -> esNodes,
        "es.port" -> "9200",
        "es.resource" -> s"$esIndex/_doc",
        "es.nodes.wan.only" -> "true",
        "es.mapping.id" -> "id"
        )

        // Write DataFrame to ES
        df.write
        .format("org.elasticsearch.spark.sql")
        .options(esConfig)
        .mode("append")
        .save()
    }

    def main(args: Array[String]): Unit = {
        val spark = SparkSession.builder()
        .appName("Common ES Loader Job")
        .getOrCreate()

        // Read parameters passed to the job
        val sourceTable = sys.env.getOrElse("SOURCE_TABLE", "")
        val dataSource = sys.env.getOrElse("DATA_SOURCE", "")
        val esNodes = sys.env.getOrElse("ES_NODES", "es-host")

        require(sourceTable.nonEmpty, "SOURCE_TABLE is required")
        require(dataSource.nonEmpty, "DATA_SOURCE is required")

        // Load data to Elasticsearch
        loadToES(spark, sourceTable, dataSource, esNodes)
    }
    }
```

---

2. Trigger ES Loader from Another Job
   
Python Example to Trigger Parallel Jobs in Databricks

```python
    from databricks_api import DatabricksAPI
    import concurrent.futures

    # Initialize Databricks API client
    db = DatabricksAPI(host="https://<your-databricks-instance>", token="<your-token>")

    # List of ES Loader job invocations
    jobs = [
        {"source_table": "/mnt/datalake/sourceA", "data_source": "sourceA"},
        {"source_table": "/mnt/datalake/sourceB", "data_source": "sourceB"},
        {"source_table": "/mnt/datalake/sourceC", "data_source": "sourceC"}
    ]

    def trigger_es_loader(job_params):
        """Trigger ES Loader Databricks job with parameters."""
        response = db.jobs.run_now(
            job_id=<ES_LOADER_JOB_ID>,
            notebook_params={
                "SOURCE_TABLE": job_params["source_table"],
                "DATA_SOURCE": job_params["data_source"],
                "ES_NODES": "es-host"
            }
        )
        return response

    # Run multiple jobs in parallel
    with concurrent.futures.ThreadPoolExecutor() as executor:
        results = list(executor.map(trigger_es_loader, jobs))

    # Print Job Run IDs
    for res in results:
        print(f"Triggered ES Loader Job Run ID: {res['run_id']}")
```

---

Key Benefits of This Approach

- ‚úÖ Reusability: The ES loader is a single, reusable component for all pipelines.
- ‚úÖ Scalability: Multiple jobs can trigger it independently.
- ‚úÖ Parallel Execution: Each data source loads its data into ES simultaneously.
- ‚úÖ Decoupled Architecture: Processing jobs focus on transformations, while the ES loader handles indexing.


---

### B. Optimizing Databricks Cluster Size for Bulk Indexing into Elasticsearch


You don‚Äôt necessarily need a 40-node Databricks cluster just because your Elasticsearch cluster has 40 data nodes. The ideal Databricks cluster size should be optimized based on Elasticsearch indexing throughput, I/O limits, and Spark parallelism.

---

#### 1. Key Considerations for Optimal Performance

1.	Elasticsearch Bulk Indexing Throughput
    -	Elasticsearch has limitations on how many documents it can ingest per second per node.
    -	If your ES cluster is already running at max throughput, adding more Databricks nodes won‚Äôt help.
    -	Check the ES cluster‚Äôs indexing rate (GET /_nodes/stats/indices) to estimate the max indexing speed.

2.	Databricks Spark Cluster Parallelism
    -	You can efficiently load 80M+ documents with a 5-10 node Databricks cluster if properly tuned.
    -	More nodes ‚â† Faster indexing if Elasticsearch is the bottleneck.
    -	You need to balance number of Spark partitions and bulk request size.

3.	Bulk Request Size & Spark Partitioning
    -	Use bulk.size tuning in elasticsearch-hadoop:
    -	Small bulk size (1MB-5MB) ‚Üí reduces memory pressure on ES.
    -	Large bulk size (50MB+) ‚Üí fewer requests but higher ES load.
    -	Adjust Spark partitions dynamically:

```scala
val partitionCount = 5 * spark.conf.get("spark.databricks.clusterUsage.numWorkers").toInt
val df = spark.read.format("delta").load("/mnt/delta/table").repartition(partitionCount)
```

4.	Networking & I/O Constraints

-	Databricks ‚Üí Elasticsearch network throughput (check es.nodes bandwidth).
-	Use dedicated ES ingest nodes to avoid overwhelming query nodes.


Recommended Cluster Setup

## **Cluster Configuration Recommendations**

| **Cluster Type**       | **Databricks Nodes** | **Driver/Worker Type**           | **Parallelism Strategy**                           |
|-----------------------|--------------------|---------------------------------|--------------------------------------------------|
| **High-Performance**  | 8-10              | 16-32 cores, high RAM           | 3-5 partitions per node, 5MB bulk size           |
| **Balanced (Cost vs. Speed)** | 5-6       | 8-16 cores                      | 2-4 partitions per node, 5-10MB bulk size        |
| **Minimal Setup**     | 3-4               | 8 cores                          | 2 partitions per node, 1-5MB bulk size           |



---

#### 2. Scala Spark Code to Optimize Bulk Indexing

```scala
import org.apache.spark.sql.SparkSession
import org.elasticsearch.spark.sql._

val spark = SparkSession.builder()
  .appName("ES Bulk Load")
  .getOrCreate()

// Read data from Delta Lake
val df = spark.read.format("delta").load("/mnt/delta/table")

// Dynamically set partitions based on cluster size
val numPartitions = 5 * spark.conf.get("spark.databricks.clusterUsage.numWorkers").toInt
val partitionedDF = df.repartition(numPartitions)

// Elasticsearch config
val esConfig = Map(
  "es.nodes" -> "es-host",
  "es.port" -> "9200",
  "es.resource" -> "my_index/_doc",
  "es.batch.size.bytes" -> "5242880", // 5MB bulk size
  "es.batch.size.entries" -> "5000",  // Tune based on ES response times
  "es.nodes.wan.only" -> "true",
  "es.mapping.id" -> "id"
)

// Write to ES
partitionedDF.write
  .format("org.elasticsearch.spark.sql")
  .options(esConfig)
  .mode("append")
  .save()
```

**Conclusion**

üöÄ Best Approach:
-	Start with 5-10 Databricks nodes (not 40).
-	Monitor ES indexing rate (_nodes/stats/indices).
-	Use 3-5 partitions per worker for optimal parallelism.
-	Optimize bulk.size to match Elasticsearch throughput.

---

### C. Monitoring Elasticsearch Ingestion in Databricks Workflow

To ensure optimal performance, we need to monitor the indexing rate, errors, and cluster resource usage in Elasticsearch while loading data from Databricks. This can help identify bottlenecks and dynamically adjust Spark partitioning or bulk settings.

---

#### 1. Key Metrics to Monitor in Elasticsearch

You can monitor these using Elasticsearch APIs:

1.	Indexing Throughput (documents per second):

```bash
GET _nodes/stats/indices
```

Look for:
-	indexing.index_total (Total docs indexed)
-	indexing.index_current (Docs currently being indexed)
-	indexing.index_time_in_millis (Time taken)

2.	Bulk Request Rejections (if ES is overloaded):

```bash
GET _nodes/stats/thread_pool
```

Look for:
-	bulk.rejected (Too many bulk requests)
-	bulk.queue (Queue size)


3.	Cluster Resource Usage (CPU, Memory, Disk I/O):

```bash
GET _cluster/stats
```

-	jvm.mem.heap_used_percent (Memory pressure)
-	fs.total.available_in_bytes (Disk space)
-	indices.store.size_in_bytes (Total index size)

---

2. Collect and Analyze ES Metrics in Databricks

You can use Databricks to query ES stats and log indexing progress.

Python Code to Monitor ES Indexing from Databricks

```python
import requests
import time

ES_HOST = "http://es-host:9200"

def get_es_indexing_stats():
    """Fetch Elasticsearch indexing statistics."""
    stats_url = f"{ES_HOST}/_nodes/stats/indices"
    response = requests.get(stats_url).json()
    
    total_docs = 0
    index_time = 0
    for node_id, data in response['nodes'].items():
        total_docs += data['indices']['indexing']['index_total']
        index_time += data['indices']['indexing']['index_time_in_millis']

    return total_docs, index_time / 1000  # Convert to seconds

def monitor_es_indexing(target_docs, sleep_interval=10):
    """Monitor ES indexing progress in real-time."""
    start_docs, _ = get_es_indexing_stats()
    
    while True:
        time.sleep(sleep_interval)
        current_docs, index_time = get_es_indexing_stats()
        indexed_docs = current_docs - start_docs
        
        print(f"Indexed {indexed_docs}/{target_docs} docs in {index_time} sec")
        
        if indexed_docs >= target_docs:
            print("Indexing complete!")
            break

# Monitor progress (e.g., 80M docs)
monitor_es_indexing(target_docs=80000000)
```

üìå This script will:
-	Poll ES every 10 seconds.
-	Print the number of indexed docs vs. the target (80M).
-	Stop when indexing is complete.


---

#### 3. Dynamic Tuning of Bulk Size & Parallelism in Databricks

Based on ES indexing rate, we can adjust the bulk size dynamically.

Scala Spark Code for Adaptive Bulk Size

```scala
import org.apache.spark.sql.{DataFrame, SparkSession}
import org.elasticsearch.spark.sql._
import scala.io.Source

def getESBulkRejections(esHost: String): Int = {
  val url = s"$esHost/_nodes/stats/thread_pool"
  val json = Source.fromURL(url).mkString
  val regex = """"bulk"\s*:\s*{\s*"rejected"\s*:\s*(\d+)""".r
  regex.findFirstMatchIn(json).map(_.group(1).toInt).getOrElse(0)
}

def adaptiveBulkSize(esHost: String): Int = {
  val rejections = getESBulkRejections(esHost)
  if (rejections > 0) {
    println(s"High bulk rejections detected ($rejections), reducing batch size...")
    2000 // Reduce batch size if ES is rejecting requests
  } else {
    5000 // Use higher batch size for optimal performance
  }
}

// Function to load data to Elasticsearch with adaptive tuning
def loadToES(df: DataFrame, esHost: String): Unit = {
  val batchSize = adaptiveBulkSize(esHost)

  val esConfig = Map(
    "es.nodes" -> esHost,
    "es.port" -> "9200",
    "es.resource" -> "my_index/_doc",
    "es.batch.size.entries" -> batchSize.toString, // Adjust dynamically
    "es.nodes.wan.only" -> "true",
    "es.mapping.id" -> "id"
  )

  df.write
    .format("org.elasticsearch.spark.sql")
    .options(esConfig)
    .mode("append")
    .save()
}

// Usage
val spark = SparkSession.builder().appName("ES Bulk Load with Monitoring").getOrCreate()
val df = spark.read.format("delta").load("/mnt/delta/table")
loadToES(df, "es-host")
```

----

#### 4. Visualizing Metrics in Databricks

- Use Databricks SQL to log indexing speed into a table:
```sql
CREATE TABLE es_indexing_log (
    timestamp STRING,
    indexed_docs BIGINT,
    total_docs BIGINT
);

INSERT INTO es_indexing_log VALUES (current_timestamp(), 500000, 80000000);
```

-	Use Databricks Dashboards to visualize:
    -	Documents Indexed over Time
    -	ES Bulk Rejections
    -	ES Cluster Load (CPU, Memory)

---

#### Final Strategy

üöÄ Key Steps for Optimized ES Ingestion in Databricks
1.	Monitor ES indexing rate & bulk rejections via _nodes/stats.
2.	Dynamically adjust bulk size to prevent overload.
3.	Parallelize Spark writes based on ES indexing throughput.
4.	Log indexing progress in Databricks for real-time monitoring.
5.	Visualize ingestion trends using SQL Dashboards.

---

### D. Databricks Workflow: Managing Multiple ES Loader Jobs & Cluster Sharing


When a single processing job produces multiple datasets for different Elasticsearch indices, it can trigger multiple asynchronous ES loader jobs. Whether each loader job runs on a new cluster or shares an existing cluster depends on Databricks job configuration.

---

#### 1. Does Databricks Create a New Cluster for Each ES Load Job?

It depends on how you configure the workflow:

üîπ Case 1: Default Behavior (Each ES Loader Creates a New Cluster)
-	If each ES loader job is defined as a separate job in Databricks Workflows, by default, Databricks will create a new cluster for each job.
-	Problem: This can be expensive and may result in unnecessary cluster spin-ups.

üîπ Case 2: Shared Cluster (Efficient Approach)
-	You can configure the ES loader jobs to run on the same cluster by using:
-	Job Clusters with Multiple Tasks (Recommended)
-	Shared All-Purpose Clusters (Less efficient for production)

---

#### 2. Recommended Approach: Using a Multi-Task Job Cluster

Databricks Workflows allows you to run multiple tasks in the same job, each corresponding to a different ES loader.

‚úÖ How It Works:
-	The processing job triggers multiple ES loader tasks within the same workflow.
-	All tasks run in parallel on the same cluster, avoiding unnecessary cluster spin-ups.
-	Each task loads a specific dataset to a different ES index.

üìå Steps to Implement
1.	Create a Databricks Workflow (Multi-Task Job)
2.	Define the Main Processing Job
3.	Add Multiple ES Loader Tasks (Running in Parallel on the Same Cluster)

---

#### 3. Example: Databricks Workflow with Shared Cluster

Databricks Workflow JSON Configuration

```json
{
  "name": "Multi-Index ES Loader",
  "tasks": [
    {
      "task_key": "ProcessData",
      "notebook_task": {
        "notebook_path": "/Repos/data-processing"
      },
      "job_cluster_key": "shared_cluster"
    },
    {
      "task_key": "LoadIndex_A",
      "notebook_task": {
        "notebook_path": "/Repos/es-loader",
        "base_parameters": {"index": "index_a"}
      },
      "depends_on": [{"task_key": "ProcessData"}],
      "job_cluster_key": "shared_cluster"
    },
    {
      "task_key": "LoadIndex_B",
      "notebook_task": {
        "notebook_path": "/Repos/es-loader",
        "base_parameters": {"index": "index_b"}
      },
      "depends_on": [{"task_key": "ProcessData"}],
      "job_cluster_key": "shared_cluster"
    }
  ],
  "job_clusters": [
    {
      "job_cluster_key": "shared_cluster",
      "new_cluster": {
        "spark_version": "13.3.x-scala2.12",
        "num_workers": 5,
        "node_type_id": "Standard_DS4_v2"
      }
    }
  ]
}
```

How This Works

‚úî Single cluster (shared_cluster) is used for all ES loader tasks
‚úî Tasks run in parallel, loading different datasets into different indices
‚úî No unnecessary cluster spin-ups, saving cost


---

#### 4. Alternative: Using an All-Purpose Cluster (Not Recommended)


-	You can manually configure multiple jobs to use the same interactive all-purpose cluster.
-	However, Databricks does not automatically manage scaling for all-purpose clusters like it does for job clusters.
-	Best for development/testing, not production.


Configuring Multiple Jobs to Use the Same Cluster
-	Use the Cluster ID in job settings.
-	Example using Databricks API:

```bash
databricks jobs create --json '{
  "name": "ES Loader A",
  "existing_cluster_id": "cluster-id-123",
  "notebook_task": {
    "notebook_path": "/Repos/es-loader",
    "base_parameters": {"index": "index_a"}
  }
}'
```

üö® Downside:
-	Manual scaling.
-	Risk of cluster overload if too many jobs run at once.


---

5. Best Practice Summary

**Best Practice Summary**

| **Approach** | **Cluster Usage** | **Cost Efficiency** | **Parallel Execution** | **Scaling** |
|-------------|----------------|-----------------|----------------|---------|
| **Separate Clusters (Default)** | New cluster per ES loader | ‚ùå Expensive | ‚úÖ Yes | ‚úÖ Auto |
| **Multi-Task Workflow (Recommended)** | One shared job cluster | ‚úÖ Cost-efficient | ‚úÖ Yes | ‚úÖ Auto |
| **All-Purpose Cluster** | Manually assigned | ‚ö†Ô∏è Moderate | ‚úÖ Yes | ‚ùå Manual |

---

**Recommended Cluster Setup**

| **Cluster Type** | **Usage Scenario** | **Advantages** | **Disadvantages** |
|-----------------|------------------|---------------|----------------|
| **Job Cluster (Multi-Task Workflow) ‚úÖ (Recommended)** | Running multiple ES loader tasks in parallel | ‚úÖ Cost-efficient <br> ‚úÖ Auto-scaling <br> ‚úÖ Optimized resource usage | ‚ùå Cluster termination after job completion |
| **All-Purpose Cluster (Manual) ‚ö†Ô∏è** | Development & debugging | ‚úÖ Persistent cluster <br> ‚úÖ Shared across multiple jobs | ‚ùå Higher cost <br> ‚ùå Manual scaling <br> ‚ùå Risk of resource contention |
| **Dedicated Cluster (Per Job) ‚ùå (Not Recommended)** | Running each ES load job separately | ‚úÖ Isolated workloads <br> ‚úÖ No resource contention | ‚ùå Expensive <br> ‚ùå Slow due to cluster spin-up time |



**Conclusion: Use a Multi-Task Workflow for Shared Clusters**

üöÄ The best approach is to define multiple ES loader tasks within the same Databricks workflow, using a single job cluster.
-	Saves cost by avoiding unnecessary cluster creation.
-	Runs ES loading jobs in parallel for faster indexing.
-	Auto-scales efficiently based on workload demand.


---

### E. Generic Elasticsearch (ES) Loader

you can design a generic Elasticsearch (ES) loader in Databricks to be shared across multiple data pipelines. This loader can dynamically determine the target ES index and parameters based on the data source metadata.


#### 1. Approach

1.	Define a Generic ES Loader:
-	Accepts dataframe, data source metadata, and ES configurations as parameters.
-	Dynamically sets the index and other parameters.
-	Uses Spark‚Äôs org.elasticsearch.spark.sql connector to write data.

2.	Use Metadata to Determine Index:
-	Define a mapping between data sources and ES indices.
-	The mapping can be stored in a config file, database, or hardcoded in logic.

3.	Pass Data Source at Runtime:
-	The pipeline calling the ES loader will pass the data source metadata dynamically.

---
#### 2. Scala Spark Implementation

```scala
import org.apache.spark.sql.{DataFrame, SparkSession}
import org.elasticsearch.spark.sql._

object ESLoader {

  /**
    * Generic function to load data into Elasticsearch.
    *
    * @param df           Input DataFrame
    * @param dataSource   The data source identifier (used to determine the ES index)
    * @param esNodes      Elasticsearch cluster nodes
    */
  def loadToES(df: DataFrame, dataSource: String, esNodes: String): Unit = {
    // Define a mapping of data sources to ES indices
    val indexMapping: Map[String, String] = Map(
      "sourceA" -> "index_a",
      "sourceB" -> "index_b",
      "sourceC" -> "index_c"
    )

    // Determine the index based on the data source
    val esIndex = indexMapping.getOrElse(dataSource, "default_index")

    // Elasticsearch write configuration
    val esConfig = Map(
      "es.nodes" -> esNodes,
      "es.port" -> "9200",
      "es.resource" -> s"$esIndex/_doc",
      "es.nodes.wan.only" -> "true",
      "es.mapping.id" -> "id" // Assume 'id' column as document ID
    )

    // Write DataFrame to Elasticsearch
    df.write
      .format("org.elasticsearch.spark.sql")
      .options(esConfig)
      .mode("append") // or "overwrite" based on requirements
      .save()
  }
}
```
---
#### 3. Usage in Data Pipeline

Each pipeline can call the loader and pass the data source dynamically:

```scala
// Sample Spark session
val spark = SparkSession.builder()
  .appName("ES Loader Pipeline")
  .config("spark.es.nodes", "es-host:9200")
  .getOrCreate()

// Sample DataFrame
val sampleDF = spark.read.option("header", "true").csv("/path/to/data.csv")

// Pass data source dynamically
ESLoader.loadToES(sampleDF, dataSource = "sourceA", esNodes = "es-host")
```

---

Benefits of This Approach

- ‚úÖ Reusable Component: A single ES loader handles multiple pipelines.
- ‚úÖ Dynamic Indexing: Different indices are determined at runtime based on the data source.
- ‚úÖ Scalability: Supports multiple indices without modifying the core logic.
- ‚úÖ Easy Integration: Can be called from different workflows in Databricks.


